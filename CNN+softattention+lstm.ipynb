{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmiYziXIQBOD",
        "outputId": "a87a31a1-3e22-4e7a-af82-9a821ed1cc36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec  4 16:04:17 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    31W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrA-CdP8QIni",
        "outputId": "c7c748f2-965b-424f-d1ab-6a731cf3a57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrkMkSAlQt4j",
        "outputId": "4baecec9-025c-4faf-88f9-95b47973f6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "import os\n",
        "#os.mkdir(r\"C:\\rafid\\augmentation\\covid\\covid aug\\photometric\")\n",
        "\n",
        "input_folder=\"/content/drive/MyDrive/rhd_model/Furier_transform\"\n",
        "\n",
        "\n",
        "output=\"/content/\"\n",
        "\n",
        "\n",
        "\n",
        "splitfolders.ratio(input_folder, output, seed=42, ratio=(.8,.1,.1)) ### train 80%, val 10%, test 20%\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLLQNSxoQy25",
        "outputId": "c5b550c7-b69c-4f56-9a18-d8349f71cd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 5882 files [03:45, 26.10 files/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_applications==1.0.4 --no-deps"
      ],
      "metadata": {
        "id": "9C2SxNJvQ-OC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b6c169-367a-4dd6-c2b3-b96fb50ad94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_applications==1.0.4\n",
            "  Downloading Keras_Applications-1.0.4-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Soft Attention\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer,InputSpec\n",
        "import keras.layers as kl\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "class SoftAttention(Layer):\n",
        "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
        "        self.channels=int(ch)\n",
        "        self.multiheads = m\n",
        "        self.aggregate_channels = aggregate\n",
        "        self.concat_input_with_scaled = concat_with_x\n",
        "\n",
        "\n",
        "        super(SoftAttention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "\n",
        "        self.i_shape = input_shape\n",
        "\n",
        "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
        "\n",
        "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
        "\n",
        "        if self.aggregate_channels==False:\n",
        "\n",
        "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
        "        else:\n",
        "            if self.concat_input_with_scaled:\n",
        "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
        "            else:\n",
        "                self.out_features_shape = input_shape\n",
        "\n",
        "\n",
        "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
        "                                        initializer='he_uniform',\n",
        "                                        name='kernel_conv3d')\n",
        "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
        "                                      initializer='zeros',\n",
        "                                      name='bias_conv3d')\n",
        "\n",
        "        super(SoftAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        exp_x = K.expand_dims(x,axis=-1)\n",
        "\n",
        "        c3d = K.conv3d(exp_x,\n",
        "                     kernel=self.kernel_conv3d,\n",
        "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
        "        conv3d = K.bias_add(c3d,\n",
        "                        self.bias_conv3d)\n",
        "        conv3d = kl.Activation('relu')(conv3d)\n",
        "\n",
        "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
        "\n",
        "\n",
        "        conv3d = K.squeeze(conv3d, axis=-1)\n",
        "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
        "\n",
        "        softmax_alpha = K.softmax(conv3d, axis=-1)\n",
        "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
        "\n",
        "\n",
        "        if self.aggregate_channels==False:\n",
        "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)\n",
        "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
        "\n",
        "            x_exp = K.expand_dims(x,axis=-2)\n",
        "\n",
        "            u = kl.Multiply()([exp_softmax_alpha, x_exp])\n",
        "\n",
        "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
        "\n",
        "        else:\n",
        "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
        "\n",
        "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
        "\n",
        "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
        "\n",
        "            u = kl.Multiply()([exp_softmax_alpha, x])\n",
        "\n",
        "        if self.concat_input_with_scaled:\n",
        "            o = kl.Concatenate(axis=-1)([u,x])\n",
        "        else:\n",
        "            o = u\n",
        "\n",
        "        return [o, softmax_alpha]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(SoftAttention,self).get_config()\n",
        ""
      ],
      "metadata": {
        "id": "loBDE8dISOZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "model = Conv2D(32, kernel_size=(3, 3), strides=2, padding=\"same\", activation=\"relu\")(inputs)\n",
        "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
        "model = Conv2D(64, kernel_size=(3, 3), strides=2, padding=\"same\", activation=\"relu\")(model)\n",
        "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
        "model = Conv2D(64, kernel_size=(3, 3), strides=2, padding=\"same\", activation=\"relu\")(model)\n",
        "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
        "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gU9YRJDTeGSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.applications.model(\n",
        "#     include_top=True,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_tensor=None,\n",
        "#     input_shape=None,\n",
        "#     pooling=None,\n",
        "\n",
        "# )\n",
        "# # Exclude the last 28 layers of the model.\n",
        "#conv = mobilenet.layers[-8].output"
      ],
      "metadata": {
        "id": "m_LLLiZqSPLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer,InputSpec\n",
        "import keras.layers as kl\n",
        "from glob import glob\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from  matplotlib import pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n",
        "%matplotlib inline\n",
        "import shutil\n",
        "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n",
        "from tensorflow.python.platform import build_info as tf_build_info\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(model.shape[-1]),name='soft_attention')(model)\n",
        "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
        "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(model))\n",
        "\n",
        "conv = concatenate([conv,attention_layer])\n",
        "conv  = Activation('relu')(conv)\n",
        "conv = Dropout(0.5)(conv)\n",
        "\n",
        "\n",
        "output = Flatten()(conv)\n",
        "output = Reshape(target_shape=(16, 8))(output)\n",
        "output = LSTM(128, activation=\"tanh\")(output)\n",
        "output = Dense(4, activation='softmax')(output)\n",
        "model = Model(inputs=inputs, outputs=output)\n"
      ],
      "metadata": {
        "id": "gko52p8WSXSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L2oDlKP4sf1",
        "outputId": "881b3455-e1ee-4df7-de47-359e9d5ed7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 112, 112, 32  896         ['input_11[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_137 (MaxPooling2  (None, 56, 56, 32)  0           ['conv2d_42[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 28, 28, 64)   18496       ['max_pooling2d_137[0][0]']      \n",
            "                                                                                                  \n",
            " max_pooling2d_138 (MaxPooling2  (None, 14, 14, 64)  0           ['conv2d_43[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 64)     36928       ['max_pooling2d_138[0][0]']      \n",
            "                                                                                                  \n",
            " max_pooling2d_139 (MaxPooling2  (None, 3, 3, 64)    0           ['conv2d_44[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_140 (MaxPooling2  (None, 1, 1, 64)    0           ['max_pooling2d_139[0][0]']      \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " soft_attention (SoftAttention)  [(None, 1, 1, 64),  9232        ['max_pooling2d_140[0][0]']      \n",
            "                                 (None, 16, 1, 1)]                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_142 (MaxPooling2  (None, 1, 1, 64)    0           ['max_pooling2d_140[0][0]']      \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_141 (MaxPooling2  (None, 1, 1, 64)    0           ['soft_attention[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenate)   (None, 1, 1, 128)    0           ['max_pooling2d_142[0][0]',      \n",
            "                                                                  'max_pooling2d_141[0][0]']      \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 1, 1, 128)    0           ['concatenate_43[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_41 (Dropout)           (None, 1, 1, 128)    0           ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_40 (Flatten)           (None, 128)          0           ['dropout_41[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)           (None, 16, 8)        0           ['flatten_40[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  (None, 128)          70144       ['reshape_12[0][0]']             \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 4)            516         ['lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 136,212\n",
            "Trainable params: 136,212\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "#from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "#from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "IMAGE_SIZE = [224,224]"
      ],
      "metadata": {
        "id": "p2cSZfGUScaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sayma comment out line 2, Ritu comment out line 1 before running\n",
        "\n",
        "op = keras.optimizers.Nadam(learning_rate=0.0007,epsilon=0.1)  #for Sayma\n",
        "#op = keras.optimizers.Nadam(lr=0.0007)  # for Ritu\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=op,\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "U78eYAfwSfBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  # shear_range = 0.2,\n",
        "                                  # zoom_range = 0.2,\n",
        "                                   brightness_range=(0.4, 0.7),\n",
        "                                   vertical_flip= True,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/train',\n",
        "                                                 target_size = (224,224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "val_set = val_datagen.flow_from_directory('/content/val',\n",
        "                                            target_size = (224,224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/test',\n",
        "                                            target_size = (224,224),\n",
        "                                            batch_size = 1,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "\n",
        "\n",
        "model.optimizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rrNKUXGSjOY",
        "outputId": "5d4cd082-022d-4b87-bdd0-d781fbf1f348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4704 images belonging to 4 classes.\n",
            "Found 587 images belonging to 4 classes.\n",
            "Found 591 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Nadam',\n",
              " 'learning_rate': 0.0007,\n",
              " 'decay': 0.004,\n",
              " 'beta_1': 0.9,\n",
              " 'beta_2': 0.999,\n",
              " 'epsilon': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "filepath = r\"/content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\"\n",
        "\n",
        "### example___filepath = \"path to weight directory/breastCancer_geometric.h5\"\n",
        "\n",
        "\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_weights_only=True,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "log_csv = CSVLogger(r'/content/drive/MyDrive/mobilenet2/csv/mobilenetv2_SE_.csv', separator=',', append=False)\n",
        "### example___CSVLogger('path to logs directory/breastCancer_geometric.csv')\n",
        "\n",
        "callbacks_list = [checkpoint1,log_csv]\n",
        "\n",
        "\n",
        "r = model.fit_generator(\n",
        "    training_set,\n",
        "    epochs=100,\n",
        "    validation_data=val_set,\n",
        "    steps_per_epoch = len(training_set),\n",
        "    validation_steps=len(val_set),\n",
        "    callbacks=callbacks_list,\n",
        "    shuffle=False\n",
        "\n",
        "\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj7IqW1KSj75",
        "outputId": "2c9238bf-985b-4af6-caa0-61def9ff12fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.5517 - accuracy: 0.8472\n",
            "Epoch 1: val_accuracy improved from -inf to 0.70464, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 120s 668ms/step - loss: 0.5517 - accuracy: 0.8472 - val_loss: 1.8051 - val_accuracy: 0.7046\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9729\n",
            "Epoch 2: val_accuracy improved from 0.70464 to 0.90577, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 40s 392ms/step - loss: 0.0841 - accuracy: 0.9729 - val_loss: 0.2731 - val_accuracy: 0.9058\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9778\n",
            "Epoch 3: val_accuracy did not improve from 0.90577\n",
            "102/102 [==============================] - 39s 379ms/step - loss: 0.0602 - accuracy: 0.9778 - val_loss: 0.3761 - val_accuracy: 0.8959\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9868\n",
            "Epoch 4: val_accuracy did not improve from 0.90577\n",
            "102/102 [==============================] - 39s 379ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.6002 - val_accuracy: 0.8115\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9895\n",
            "Epoch 5: val_accuracy did not improve from 0.90577\n",
            "102/102 [==============================] - 39s 380ms/step - loss: 0.0322 - accuracy: 0.9895 - val_loss: 0.4815 - val_accuracy: 0.8383\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9920\n",
            "Epoch 6: val_accuracy did not improve from 0.90577\n",
            "102/102 [==============================] - 39s 376ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.4423 - val_accuracy: 0.8523\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9929\n",
            "Epoch 7: val_accuracy did not improve from 0.90577\n",
            "102/102 [==============================] - 39s 377ms/step - loss: 0.0176 - accuracy: 0.9929 - val_loss: 0.5731 - val_accuracy: 0.8354\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9945\n",
            "Epoch 8: val_accuracy did not improve from 0.90577\n",
            "102/102 [==============================] - 39s 377ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.5278 - val_accuracy: 0.8467\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9908\n",
            "Epoch 9: val_accuracy did not improve from 0.90577\n",
            "102/102 [==============================] - 39s 380ms/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.3154 - val_accuracy: 0.9001\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9941\n",
            "Epoch 10: val_accuracy improved from 0.90577 to 0.96765, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 39s 381ms/step - loss: 0.0157 - accuracy: 0.9941 - val_loss: 0.0916 - val_accuracy: 0.9677\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9945\n",
            "Epoch 11: val_accuracy did not improve from 0.96765\n",
            "102/102 [==============================] - 38s 375ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.3609 - val_accuracy: 0.8833\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9972\n",
            "Epoch 12: val_accuracy did not improve from 0.96765\n",
            "102/102 [==============================] - 39s 376ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.3803 - val_accuracy: 0.8861\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9969\n",
            "Epoch 13: val_accuracy did not improve from 0.96765\n",
            "102/102 [==============================] - 38s 375ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.2174 - val_accuracy: 0.9226\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9975\n",
            "Epoch 14: val_accuracy improved from 0.96765 to 0.97187, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 39s 380ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 0.0744 - val_accuracy: 0.9719\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9966\n",
            "Epoch 15: val_accuracy did not improve from 0.97187\n",
            "102/102 [==============================] - 38s 375ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.1256 - val_accuracy: 0.9592\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9982\n",
            "Epoch 16: val_accuracy improved from 0.97187 to 0.97609, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 39s 379ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0512 - val_accuracy: 0.9761\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9969\n",
            "Epoch 17: val_accuracy did not improve from 0.97609\n",
            "102/102 [==============================] - 39s 377ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.1761 - val_accuracy: 0.9522\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9966\n",
            "Epoch 18: val_accuracy did not improve from 0.97609\n",
            "102/102 [==============================] - 38s 375ms/step - loss: 0.0083 - accuracy: 0.9966 - val_loss: 0.1448 - val_accuracy: 0.9634\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
            "Epoch 19: val_accuracy did not improve from 0.97609\n",
            "102/102 [==============================] - 39s 377ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0841 - val_accuracy: 0.9747\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n",
            "Epoch 20: val_accuracy did not improve from 0.97609\n",
            "102/102 [==============================] - 38s 374ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0697 - val_accuracy: 0.9761\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9997\n",
            "Epoch 21: val_accuracy did not improve from 0.97609\n",
            "102/102 [==============================] - 39s 378ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0951 - val_accuracy: 0.9719\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9982\n",
            "Epoch 22: val_accuracy improved from 0.97609 to 0.98453, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 39s 379ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0505 - val_accuracy: 0.9845\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
            "Epoch 23: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 39s 376ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.1407 - val_accuracy: 0.9606\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
            "Epoch 24: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 374ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1382 - val_accuracy: 0.9578\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9978\n",
            "Epoch 25: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 39s 378ms/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.1308 - val_accuracy: 0.9620\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9988\n",
            "Epoch 26: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 374ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.1014 - val_accuracy: 0.9691\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 27: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 375ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1026 - val_accuracy: 0.9691\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n",
            "Epoch 28: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 376ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.1571 - val_accuracy: 0.9550\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9978\n",
            "Epoch 29: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 375ms/step - loss: 0.0030 - accuracy: 0.9978 - val_loss: 0.0579 - val_accuracy: 0.9817\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9997\n",
            "Epoch 30: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 375ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0759 - val_accuracy: 0.9789\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9982\n",
            "Epoch 31: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.1407 - val_accuracy: 0.9620\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
            "Epoch 32: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 374ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.1043 - val_accuracy: 0.9705\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9991\n",
            "Epoch 33: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0667 - val_accuracy: 0.9803\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 34: val_accuracy did not improve from 0.98453\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.1616 - val_accuracy: 0.9620\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9975\n",
            "Epoch 35: val_accuracy improved from 0.98453 to 0.99015, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 39s 378ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0249 - val_accuracy: 0.9902\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 7.8820e-04 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99015\n",
            "102/102 [==============================] - 38s 376ms/step - loss: 7.8820e-04 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9789\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 5.8844e-04 - accuracy: 0.9997\n",
            "Epoch 37: val_accuracy improved from 0.99015 to 0.99156, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 39s 378ms/step - loss: 5.8844e-04 - accuracy: 0.9997 - val_loss: 0.0301 - val_accuracy: 0.9916\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 6.6065e-04 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 375ms/step - loss: 6.6065e-04 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9775\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 39: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.1241 - val_accuracy: 0.9677\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 8.8828e-04 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 8.8828e-04 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9887\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 7.5066e-04 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 374ms/step - loss: 7.5066e-04 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9775\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 42: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0762 - val_accuracy: 0.9775\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 6.8303e-04 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 370ms/step - loss: 6.8303e-04 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9578\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 39s 375ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0601 - val_accuracy: 0.9845\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 45: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1193 - val_accuracy: 0.9662\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9988\n",
            "Epoch 46: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.1304 - val_accuracy: 0.9592\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.6786e-04 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 4.6786e-04 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9648\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 2.9860e-04 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99156\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 2.9860e-04 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9873\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy improved from 0.99156 to 0.99297, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 39s 379ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0287 - val_accuracy: 0.9930\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 50: val_accuracy did not improve from 0.99297\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0339 - val_accuracy: 0.9930\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 8.9451e-04 - accuracy: 0.9997\n",
            "Epoch 51: val_accuracy improved from 0.99297 to 0.99437, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 39s 376ms/step - loss: 8.9451e-04 - accuracy: 0.9997 - val_loss: 0.0221 - val_accuracy: 0.9944\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.2020e-04 - accuracy: 1.0000\n",
            "Epoch 52: val_accuracy did not improve from 0.99437\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 4.2020e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9944\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
            "Epoch 53: val_accuracy did not improve from 0.99437\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0271 - val_accuracy: 0.9930\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.8861e-04 - accuracy: 1.0000\n",
            "Epoch 54: val_accuracy improved from 0.99437 to 0.99578, saving model to /content/drive/MyDrive/mobilenet2/h5/mobilenetv2_SE_.h5\n",
            "102/102 [==============================] - 38s 374ms/step - loss: 4.8861e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9958\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.1184e-04 - accuracy: 1.0000\n",
            "Epoch 55: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 4.1184e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9958\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 6.1943e-04 - accuracy: 1.0000\n",
            "Epoch 56: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 370ms/step - loss: 6.1943e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9958\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 2.6038e-04 - accuracy: 1.0000\n",
            "Epoch 57: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 375ms/step - loss: 2.6038e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9930\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.8735e-04 - accuracy: 1.0000\n",
            "Epoch 58: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 4.8735e-04 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9958\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 6.4818e-04 - accuracy: 1.0000\n",
            "Epoch 59: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 6.4818e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9930\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 3.4918e-04 - accuracy: 1.0000\n",
            "Epoch 60: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 3.4918e-04 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9958\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9994\n",
            "Epoch 61: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0311 - val_accuracy: 0.9902\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 62: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 369ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0484 - val_accuracy: 0.9817\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 7.1087e-04 - accuracy: 0.9997\n",
            "Epoch 63: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 7.1087e-04 - accuracy: 0.9997 - val_loss: 0.0514 - val_accuracy: 0.9845\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 7.5314e-04 - accuracy: 1.0000\n",
            "Epoch 64: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 7.5314e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9916\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9994\n",
            "Epoch 65: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0187 - val_accuracy: 0.9930\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 1.9659e-04 - accuracy: 1.0000\n",
            "Epoch 66: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 1.9659e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9944\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 3.6330e-04 - accuracy: 1.0000\n",
            "Epoch 67: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 3.6330e-04 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9958\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 2.2662e-04 - accuracy: 1.0000\n",
            "Epoch 68: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 2.2662e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9902\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 7.5451e-04 - accuracy: 1.0000\n",
            "Epoch 69: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 7.5451e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9958\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.9691e-04 - accuracy: 0.9997\n",
            "Epoch 70: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 4.9691e-04 - accuracy: 0.9997 - val_loss: 0.0208 - val_accuracy: 0.9944\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 8.2971e-04 - accuracy: 0.9997\n",
            "Epoch 71: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 370ms/step - loss: 8.2971e-04 - accuracy: 0.9997 - val_loss: 0.0156 - val_accuracy: 0.9930\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 3.7945e-04 - accuracy: 1.0000\n",
            "Epoch 72: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 3.7945e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9958\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 9.3651e-04 - accuracy: 0.9997\n",
            "Epoch 73: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 370ms/step - loss: 9.3651e-04 - accuracy: 0.9997 - val_loss: 0.0201 - val_accuracy: 0.9916\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 1.2806e-04 - accuracy: 1.0000\n",
            "Epoch 74: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 1.2806e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9930\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 2.1455e-04 - accuracy: 1.0000\n",
            "Epoch 75: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 370ms/step - loss: 2.1455e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9944\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 6.1852e-04 - accuracy: 0.9997\n",
            "Epoch 76: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 6.1852e-04 - accuracy: 0.9997 - val_loss: 0.0779 - val_accuracy: 0.9817\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 6.3587e-04 - accuracy: 0.9997\n",
            "Epoch 77: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 6.3587e-04 - accuracy: 0.9997 - val_loss: 0.0411 - val_accuracy: 0.9902\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 2.3210e-04 - accuracy: 1.0000\n",
            "Epoch 78: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 374ms/step - loss: 2.3210e-04 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9887\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.3003e-04 - accuracy: 1.0000\n",
            "Epoch 79: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 4.3003e-04 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9944\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 5.1377e-04 - accuracy: 1.0000\n",
            "Epoch 80: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 5.1377e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9930\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 1.1912e-04 - accuracy: 1.0000\n",
            "Epoch 81: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 1.1912e-04 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9902\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9991\n",
            "Epoch 82: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 0.1051 - val_accuracy: 0.9733\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 6.4510e-04 - accuracy: 0.9997\n",
            "Epoch 83: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 6.4510e-04 - accuracy: 0.9997 - val_loss: 0.1365 - val_accuracy: 0.9677\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 6.5780e-04 - accuracy: 1.0000\n",
            "Epoch 84: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 6.5780e-04 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9775\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 85: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1390 - val_accuracy: 0.9662\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
            "Epoch 86: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 370ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0419 - val_accuracy: 0.9887\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
            "Epoch 87: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0946 - val_accuracy: 0.9747\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 1.4257e-04 - accuracy: 1.0000\n",
            "Epoch 88: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 1.4257e-04 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9733\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 2.9304e-04 - accuracy: 1.0000\n",
            "Epoch 89: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 2.9304e-04 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9845\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9991\n",
            "Epoch 90: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 374ms/step - loss: 0.0015 - accuracy: 0.9991 - val_loss: 0.0499 - val_accuracy: 0.9845\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 5.3620e-04 - accuracy: 1.0000\n",
            "Epoch 91: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 5.3620e-04 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9902\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
            "Epoch 92: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 370ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0492 - val_accuracy: 0.9873\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 3.0259e-04 - accuracy: 1.0000\n",
            "Epoch 93: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 373ms/step - loss: 3.0259e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9859\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.7372e-04 - accuracy: 1.0000\n",
            "Epoch 94: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 4.7372e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9930\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.8321e-04 - accuracy: 0.9997\n",
            "Epoch 95: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 4.8321e-04 - accuracy: 0.9997 - val_loss: 0.1588 - val_accuracy: 0.9634\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 4.4929e-04 - accuracy: 1.0000\n",
            "Epoch 96: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 371ms/step - loss: 4.4929e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9902\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 1.9916e-04 - accuracy: 1.0000\n",
            "Epoch 97: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 1.9916e-04 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9930\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 3.8900e-04 - accuracy: 0.9997\n",
            "Epoch 98: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 3.8900e-04 - accuracy: 0.9997 - val_loss: 0.1064 - val_accuracy: 0.9733\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9991\n",
            "Epoch 99: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 0.0014 - accuracy: 0.9991 - val_loss: 0.0702 - val_accuracy: 0.9803\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - ETA: 0s - loss: 1.0722e-04 - accuracy: 1.0000\n",
            "Epoch 100: val_accuracy did not improve from 0.99578\n",
            "102/102 [==============================] - 38s 372ms/step - loss: 1.0722e-04 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "filepath = r\"/content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\"\n",
        "\n",
        "### example___filepath = \"path to weight directory/breastCancer_geometric.h5\"\n",
        "\n",
        "\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_weights_only=True,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "log_csv = CSVLogger(r'/content/drive/MyDrive/rhd_model/csv/mobilenetv2_SE_.csv', separator=',', append=False)\n",
        "### example___CSVLogger('path to logs directory/breastCancer_geometric.csv')\n",
        "\n",
        "callbacks_list = [checkpoint1,log_csv]\n",
        "\n",
        "\n",
        "r = model.fit_generator(\n",
        "    training_set,\n",
        "    epochs=100,\n",
        "    validation_data=val_set,\n",
        "    steps_per_epoch = len(training_set),\n",
        "    validation_steps=len(val_set),\n",
        "    callbacks=callbacks_list,\n",
        "    shuffle=False\n",
        "\n",
        "\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d3e-5Bx68SoJ",
        "outputId": "8c4feada-042c-4481-844c-b0739571f622"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.9005\n",
            "Epoch 1: val_accuracy improved from -inf to 0.64055, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 117s 445ms/step - loss: 0.3408 - accuracy: 0.9005 - val_loss: 2.0099 - val_accuracy: 0.6405\n",
            "Epoch 2/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9756\n",
            "Epoch 2: val_accuracy improved from 0.64055 to 0.64736, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 56s 382ms/step - loss: 0.0655 - accuracy: 0.9756 - val_loss: 2.3511 - val_accuracy: 0.6474\n",
            "Epoch 3/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9898\n",
            "Epoch 3: val_accuracy did not improve from 0.64736\n",
            "147/147 [==============================] - 53s 358ms/step - loss: 0.0327 - accuracy: 0.9898 - val_loss: 3.0829 - val_accuracy: 0.6440\n",
            "Epoch 4/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9889\n",
            "Epoch 4: val_accuracy did not improve from 0.64736\n",
            "147/147 [==============================] - 53s 356ms/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 2.3917 - val_accuracy: 0.6474\n",
            "Epoch 5/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9909\n",
            "Epoch 5: val_accuracy improved from 0.64736 to 0.65417, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 54s 369ms/step - loss: 0.0212 - accuracy: 0.9909 - val_loss: 2.3660 - val_accuracy: 0.6542\n",
            "Epoch 6/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9949\n",
            "Epoch 6: val_accuracy improved from 0.65417 to 0.67462, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 54s 363ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 2.0643 - val_accuracy: 0.6746\n",
            "Epoch 7/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9943\n",
            "Epoch 7: val_accuracy improved from 0.67462 to 0.70017, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 53s 361ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 1.4460 - val_accuracy: 0.7002\n",
            "Epoch 8/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9955\n",
            "Epoch 8: val_accuracy improved from 0.70017 to 0.73083, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 53s 360ms/step - loss: 0.0111 - accuracy: 0.9955 - val_loss: 1.5946 - val_accuracy: 0.7308\n",
            "Epoch 9/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9964\n",
            "Epoch 9: val_accuracy improved from 0.73083 to 0.73424, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 53s 360ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 1.5444 - val_accuracy: 0.7342\n",
            "Epoch 10/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
            "Epoch 10: val_accuracy improved from 0.73424 to 0.87394, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 53s 360ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.4226 - val_accuracy: 0.8739\n",
            "Epoch 11/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9983\n",
            "Epoch 11: val_accuracy improved from 0.87394 to 0.87734, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 53s 362ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.4318 - val_accuracy: 0.8773\n",
            "Epoch 12/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9983\n",
            "Epoch 12: val_accuracy did not improve from 0.87734\n",
            "147/147 [==============================] - 52s 354ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.4845 - val_accuracy: 0.8722\n",
            "Epoch 13/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9979\n",
            "Epoch 13: val_accuracy improved from 0.87734 to 0.88075, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 53s 359ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.3872 - val_accuracy: 0.8807\n",
            "Epoch 14/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9966\n",
            "Epoch 14: val_accuracy improved from 0.88075 to 0.96934, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 54s 364ms/step - loss: 0.0086 - accuracy: 0.9966 - val_loss: 0.0935 - val_accuracy: 0.9693\n",
            "Epoch 15/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9964\n",
            "Epoch 15: val_accuracy improved from 0.96934 to 0.97274, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 53s 362ms/step - loss: 0.0069 - accuracy: 0.9964 - val_loss: 0.0744 - val_accuracy: 0.9727\n",
            "Epoch 16/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9977\n",
            "Epoch 16: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 53s 356ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.2615 - val_accuracy: 0.9233\n",
            "Epoch 17/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 355ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.1125 - val_accuracy: 0.9574\n",
            "Epoch 18/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998\n",
            "Epoch 18: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 355ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.5280 - val_accuracy: 0.8722\n",
            "Epoch 19/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 53s 357ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1862 - val_accuracy: 0.9438\n",
            "Epoch 20/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
            "Epoch 20: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 354ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.3657 - val_accuracy: 0.8944\n",
            "Epoch 21/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
            "Epoch 21: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 354ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 1.2722 - val_accuracy: 0.7700\n",
            "Epoch 22/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9979\n",
            "Epoch 22: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 355ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 1.5843 - val_accuracy: 0.7632\n",
            "Epoch 23/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
            "Epoch 23: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 354ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.2014 - val_accuracy: 0.9370\n",
            "Epoch 24/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9983\n",
            "Epoch 24: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 353ms/step - loss: 0.0033 - accuracy: 0.9983 - val_loss: 0.3747 - val_accuracy: 0.8859\n",
            "Epoch 25/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 354ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.2843 - val_accuracy: 0.9148\n",
            "Epoch 26/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9989\n",
            "Epoch 26: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 354ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.2210 - val_accuracy: 0.9336\n",
            "Epoch 27/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 354ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1023 - val_accuracy: 0.9642\n",
            "Epoch 28/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998\n",
            "Epoch 28: val_accuracy did not improve from 0.97274\n",
            "147/147 [==============================] - 52s 354ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1525 - val_accuracy: 0.9523\n",
            "Epoch 29/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9989\n",
            "Epoch 29: val_accuracy improved from 0.97274 to 0.99830, saving model to /content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\n",
            "147/147 [==============================] - 53s 359ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0154 - val_accuracy: 0.9983\n",
            "Epoch 30/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9991\n",
            "Epoch 30: val_accuracy did not improve from 0.99830\n",
            "147/147 [==============================] - 52s 353ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0099 - val_accuracy: 0.9966\n",
            "Epoch 31/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 9.1669e-04 - accuracy: 0.9996\n",
            "Epoch 31: val_accuracy did not improve from 0.99830\n",
            "147/147 [==============================] - 52s 351ms/step - loss: 9.1669e-04 - accuracy: 0.9996 - val_loss: 0.0143 - val_accuracy: 0.9966\n",
            "Epoch 32/100\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 32: val_accuracy did not improve from 0.99830\n",
            "147/147 [==============================] - 52s 352ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0092 - val_accuracy: 0.9983\n",
            "Epoch 33/100\n",
            " 10/147 [=>............................] - ETA: 43s - loss: 0.0015 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-dd024b4a2a8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(r\"/content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\")\n",
        "Adam = keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "\n",
        "preds = model.evaluate_generator(val_set)\n",
        "print (\"Loss = \",float(preds[0]))\n",
        "print (\"Test Accuracy = \",float(preds[1])*100)"
      ],
      "metadata": {
        "id": "LgFsMNsy7mPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2762bdbc-0847-467f-e629-edee8bd865f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss =  0.015381570905447006\n",
            "Test Accuracy =  99.82964396476746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(r\"/content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\")\n",
        "Adam = keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "\n",
        "preds = model.evaluate_generator(test_set)\n",
        "print (\"Loss = \",float(preds[0]))\n",
        "print (\"Test Accuracy = \",float(preds[1])*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDeRx4nnDrZK",
        "outputId": "426acd7d-f266-43dd-f933-bd358b271f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss =  0.05968766286969185\n",
            "Test Accuracy =  98.9847719669342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### loss and accuracy curve ### updated !!!!!!!!!!\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fin1= pd.read_csv(r'/content/drive/MyDrive/rhd_model/csv/mobilenetv2_SE_.csv') ###directory\n",
        "\n",
        "\n",
        "### accuracy curve ###\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(fin1['accuracy'], label='Trining accuracy')\n",
        "plt.plot(fin1['val_accuracy'], label='Validation accuracy')\n",
        "\n",
        "plt.title('Accuracy Curve')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.savefig(r'/content/drive/MyDrive/rhd_model/csv/Zrms_accuracy.png', dpi = 300)\n",
        "\n",
        "### loss curve ###\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(fin1['loss'], label='Trining loss')\n",
        "plt.plot(fin1['val_loss'], label='Validation loss')\n",
        "\n",
        "plt.title('Loss Curve')\n",
        "\n",
        "plt.savefig(r'/content/drive/MyDrive/rhd_model/csv/Zrms_loss.png', dpi = 300)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "IvMjuPgiD3z5",
        "outputId": "22cf79e5-071f-43a5-95dc-2da61f05a2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0f8b325c50>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAEICAYAAAA6InEPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXiU1dn48e+dyQYhAbK5ECCorCqLAlZRwVoULYK4UxeoFWqt1i6+rVpf19rX+rOvvlZrxbovxQWLaFEEN1xQiYAKkSUgkLBmISGQdWbO74/zTBhClkkyk8nM3J/rmmtmnm3uJ8tzz1mec8QYg1JKKRWp4sIdgFJKKdURmsiUUkpFNE1kSimlIpomMqWUUhFNE5lSSqmIpolMKaVURNNEppRSKqJpIlMxRUQ+FJE9IpIU7lhCRUTSROQhEdkqIvtEZKPzPjPcsSkVCprIVMwQkVzgNMAAUzr5s+M76XMSgfeAY4FJQBpwMlAKjG3H8TolbqU6QhOZiiVXAZ8DzwAz/FeISF8ReV1EikWkVEQe8Vs3S0S+E5FKEckXkROc5UZEjvHb7hkR+ZPzeoKIFInIH0RkJ/C0iPQWkbecz9jjvM7x2z9dRJ4Wke3O+vnO8tUicp7fdgkiUiIio5o5x37ANGNMvjHGa4zZbYy5xxizsJ1xfycik/22j3fOwfdz+IGIfCYi5SLytYhMaNuvRamO0USmYslVwIvO42wROQxARFzAW8AWIBfoA8x11l0M3Onsm4YtyZUG+HmHA+lAf2A29v/taed9P6AaeMRv++eB7tjSVDbwoLP8OeAKv+3OBXYYY1Y28Zk/At4xxuwLMMZA4v4XMN1v/dlAiTFmhYj0Af4D/MnZ5yZgnohkdeDzlWoTTWQqJojIqdgL8yvGmK+AjcBPnNVjgSOB/zLG7DfG1BhjPnHWXQPcb4xZbqwCY8yWAD/WC9xhjKk1xlQbY0qNMfOMMVXGmErgXmC8E98RwDnAtcaYPcaYemPMR85xXgDOFZE05/2V2KTXlAxgR4DxBRQ38BIwRUS6O+t/gk1uYBPsQmPMQqf0txjIwyZbpTqFJjIVK2YA7xpjSpz3L3GgerEvsMUY425iv77YpNcexcaYGt8bEekuIo+LyBYR2QssBXo5JcK+QJkxZk/jgxhjtgOfAheKSC9swnuxmc8sBY5oZ7xNxm2MKQC+A85zktkU7M8P7JeDi51qxXIRKQdODUIMSgVMG3JV1BORbsAlgMtp9wFIwiaREUAh0E9E4ptIZoXA0c0cugpbFehzOFDk977x1BK/AwYDJxljdorISGAlIM7npItIL2NMeROf9Sy2dBgPLDPGbGsmpiXAn0QkxRizP0hxw4HqxTgg30luOHE/b4yZ1cxnKRVyWiJTseB8wAMMA0Y6j6HAx9i2ry+x1XH3iUiKiCSLyDhn338CN4nIiWIdIyL9nXWrgJ+IiEtEJuFUE7YgFdsuVi4i6cAdvhXGmB3A28DfnU4hCSJyut++84ETgBuxbWbNeR6bXOaJyBARiRORDBG5VUR81X1tjRtsm+FZwC84UBoDW+15noic7Rwv2ekwktPkUZQKAU1kKhbMAJ42xmw1xuz0PbAdLS7HlojOA44BtmJLJ5cCGGNexbZlvQRUYhNKunPcG539yp3jzG8ljoeAbkAJtvfkO43WXwnUA2uB3cCvfSuctqp5wADg9eY+wBhTi+3wsRZYDOzFJupM4It2xu1LtMuAU4CX/ZYXAlOBW4FibBL9L/TaojqR6MSaSkUGEbkdGGSMuaLVjZWKIdpGplQEcKoif4YttSml/GjxX6kuTkRmYavs3jbGLA13PEp1NVq1qJRSKqJpiUwppVRE63JtZJmZmSY3NzfcYSillOpCvvrqqxJjTJNDn3W5RJabm0teXl64w1BKKdWFiEizQ8Np1aJSSqmIpolMKaVURNNEppRSKqJpIlNKKRXRNJEppZSKaK0mMhF5SkR2i8jqZtaLiDwsIgUi8o1v+nNn3QwR2eA8ZjS1v1JKKdURgZTIngEmtbD+HGCg85gNPAYNY8PdAZyEnYH3DhHp3ZFglVJKqcZavY/MGLNURHJb2GQq8JyxY119LiK9nGnbJwCLjTFlACKyGJsQ/9XskZRSATHGUOv2sr/Wzf5aD/tq3eyvc9tn57Gv1sP+WjceryHBJSS44oh3xZHgEuLj4oh3CYku+xwfZ5cnxseRmpxAWnI8ad0SSE2OJyneFe7T7RTGGKrrnZ+l87PbV+um3uMlPi6OxPgDP7cEV5z9ecb5fq7S8N7tNbg9XtxeQ53b2/C+3mNwe73U+157DPVeL/XONvUer13m8VLvO4bHUOc8e4whOSGObgkuuie6SE5w0T0xnm4JLroluhqWd3MeLhE8xuD1GrwGPF6DMfY49rVd5tvmQHwH4q332s92e7wNcbi9Xto6suGFJ+aQ4ApdS1Ywbojugx3Q1KfIWdbc8kOIyGxsaY5+/foFISTVFRhjqKrzsLemnsoaN3ur69lbU8++Wg+19R5q3V7n4aG23v6j1NY7733r6j1NTlfcHIGGC0tTFx/fhcd3YU9JshfstOR4UpMT6NktnrTkBFKTE0hOiENEgvoz8XgN+2rc7K2pP+jnUlnTOBF5Gl4f/HxgudvbOeOkJsXHHfQz8n+dFN+2i5MIuERwxQkigisO4kSIc5bFCcTFCS7xJQR74Wy4iDoX+cYXf08brqzGQHX9gUS/v9bNPufn30k/0pCb4VrEqLgNlJk0Sk0ae0il1KRSZtIoI5VSk0YFKZgOd5Mw9KCadKkkg72ky16/15VkyF56U0nd8e+S0C0pKOfWlC4xsocxZg4wB2D06NFR8qcUebxew/46N5U19lFV56a63kN1nYfqeg9VdR5qnGffsuo6+35frXNRrqlnb7Wbypp69tbY0kCgEl1xJMXHkZQQR1K8i6T4OBLj25ZMjHEubs5F0H779TZ8+7UXxsBiSnAJac6FOzXZfvO1F1shzrnouqTRBdm5CAPsr3X7/Uzsz6ey1t3q58YJpCTF0yMpnhTnkZoUT1Zq0kHLeyTFk5LoanjdIzn+4PWJ8aQkuYjzJQWvl3r3gZ9Dw8/GLyHUur1U1tQfErfv97q3pp6K6nqKyqrYW1NPvactCcQpBRiD1xi8XvA6JYSW8pCI/XKSECcNJcqGUpDzJSXO+T0Eqnuii57dEujTK5mUxEY/t+R4eiS5SEm0yxLi4w4uLTnJ1b+05F+ScTUqpSX4lXgbSsXOuTQuFTe8ds4tIf7Al684gVq31/7POf97Df+P9R6qnf9XKrYx9aMXqXOlEGfcJHr2N/kz8IqLuoRe1CX1pj6xJyL2f00EBOfZeR0n+K0zxNXtI666lLjqUsRT1/Tv25WMt3sG3m4ZuKgBunYi2wb09Xuf4yzbhq1e9F/+YRA+L2ZVVNezZnsFa7btZc32CjYW7ydOsBf9BCcJOAkgKcH+UyQlOO/j46jzGJtgnAvSwa9t8mnLN9LkhLiGqo0eSfGkdYsnOzWZY7IOVEv5SjdpDSWd+IbqqqSEOJJcroZY4+KCW/ppjk129qK0v9Z3cT6QfJv7GVXXeaj3eBuqabzOBdnjtV8CDlygDQZISbTn2je9e8O5+0ozaQf9TOw638U0FCXBxDghkThIDOphg8YYc8jPNU7sBdzVSX8XkSA5wVYpttjZ4N1/AIbkX34MvftDfQ1UlUJVCewvgaoyqCohbn8JyVUlJO8vgZoK2lRfmJIDfUZCSgZ0z4SUTOf5wHtJTMEFdEbFdDAS2QLgehGZi+3YUWGM2SEii4A/+3XwOAu4JQifFxOKK2tZvb2C/O17Wb2tgtXbKygsq25Yf0TPZAYelooAtW5b3VS6z6mec6rqGqrt3AfqtFOTDk4yR/ZKZkhy6kHL0rrF0yMpge5Jtt794Dp5W/+eHO/qtMQTbCJCYrxtD0pJiic7LTncIcU8EcElaNLqqJoKyHsGjj3fJjGAhGTo2cc+olSriUxE/oUtWWWKSBG2J2ICgDHmH8BC4FygAKgCfuqsKxORe4DlzqHu9nX8iHTGmA59Y/Z4DaX7aymprKNkXy3FlbUNz5tK9rNmewW79tY2bN8/ozvD+/Ri+th+HHdkT449Mo2MHoEX030lEFec6IVCqWi24jmoq4STrw93JJ0qkF6L01tZb4BfNrPuKeCp9oXW9RTtqeLmed/y6cYSkuMPLaX49x7yPSfGx1FRVU+xX8Iq21/XZBVetwQXfdO7Me7oTIYdmcZxfXoy7Mg00pITOhS3rwSilIpinnr4/DHIPQ36nND69lGkS3T26OqMMbyaV8Tdb+UDcM2pAwCa7ABRtr/uoI4QtW4vPbslkJmaRE7v7ozq14usHklkpSaR2eg5JUl/HUqpdlozH/Zug8kPhjuSTqdXzlbsrqzhlnnf8t7a3fzgqHT+30Uj6JvePdxhKaXUAcbAZw9D5mA4ZmK4o+l0msha8J9vdnDb/G+pqvNw++RhzDwlN2I7OCilotj3S2HnN3DewxAXe0PoaiJrQnlVHbe/sYYFX29nRE5P/nrJSI7J7hHusJRSqmmf/Q1SsmD4peGOJCw0kTXy4brd/GHeN5Tuq+O3Ewdx3YSjiQ/h0CpKKdUhu/KhYDGccZvtah+DNJE59te6uXfhd7z0xVYGZvfgyRljOK5Pz3CHpZRSLVv2KMR3gzE/C3ckYaOJDFi+uYzfvfI1hXuqmH36Ufx24iCSE2JjoFSlVASr3AnfvAwnzoTu6eGOJmxiPpHt3lvD5U98wWE9k3h59smMHRC7fwxKqQjzxePgdcPJ14U7krCK+UT24fpi6jxeHr9iNMOOTAt3OCpSeT1QvgWK10PxWti7HU6/CXpkhzsyFa1q90HekzD0PEg/KtzRhFXMJ7Kl64vJSk1i6BGp4Q5FRQJPPZR9DyXrbMIqdp5LNoC75uBt45PgrHvCE6eKfqtetGMrnvKrcEcSdjGdyDxewycFJZw55LCgjzauosy3r8HSB6C0ALz1B5b37AdZg2HAePucNQQyB8Gbv4KVz8MZt0JCt/DFraKTx207efQ9CfqOCXc0YRfTiezbbRWUV9Vz+qDMcIeiurov/mG//Z78S5ussgbbhJXUzP2FY2ZB/huweh6MuqJzY1XRb+2btir77HvDHUmXENOJbOn6YkTgtIFZ4Q5FdWV1VbB9lU1iE+8KbJ/cUyFrqG2MH3m5naFQqWAwBj592LaLDT433NF0CTF9p+/S9cUc36cn6SlddLZB1TVsX2GrE/udHPg+IjB2lh02qGh569ur2GIMLLgBnv4xFOW1bd+ty+zf5Mm/hDi9TQhiOJHtralnZWE5p2tpTLVm6zL73Hds2/YbfikkpcGXc4Ifk4ps375m5w7bvgL+eSa8Ptv2dA3EZ3+Dbukw4iehjTGCxGwi+6ygBI/XcPogTWSqFVuW2WrCtt5wmtTDViuumQ+Vu0ITm4o8e3fAwt9Bzlj47Xdw6m/t38jfToQP/2KrsptTsgHWLbSl/USdhcMnZhPZR+tL6JEUz6h+vcIdiurKvB4o/BL6t6Fa0d+Ya2y15IpngxeTJsXI5atSdNfBtH9At17wozvg+i9h4ET48M/wyBhbYjNNzL677BFwJdnORKpBTCYyYwxL1xdzytEZJOiAwKolu9bYqePb0j7mL/MYOPpMyHvK3oPWUV+/DH8dBNtWdPxYqvOteM4O8DvxLsg4+sDy3rlwyXMw8z/QvTfM+xk8dTZs++rANvuKYdW/YOR06KE1Sf4CuoqLyCQRWSciBSJycxPr+4vIeyLyjYh8KCI5fus8IrLKeSwIZvDttalkP9vKq7VaUbVu6+f2ud8P2n+MsbOhcges/U/HYqneA4tuta83vtexY6nOt2eL/f3lntZ8iSr3VJj9EUz5G5Rtgid+CP/+ha2OXP5P8NTCD37ZuXFHgFa734uIC3gUmAgUActFZIExJt9vsweA54wxz4rID4H/Aa501lUbY0YGOe4OWbq+GIDxmshUa7Yug7Q+0LNv+48xcCL06g9fPgHHnt/+47x3N1SXQUo2bPms/cdRnc/rhTd+CQhMfbTlyS/jXHDCVTDsfPj4r/D53+09iRIHg86BrEGdFnakCKRENhYoMMZsMsbUAXOBqY22GQa877z+oIn1XcrS9cUMyEyhb7o2lqoWGGMTWb8fdOw+sDiXnWJjyye2qrI9ir6CvKfhpGth2BTY+kVwqipV51j+BGz+GCb9GXr3D2yf5DRbBfnLL+CYH0J9FZz6m9DGGaECSWR9gEK/90XOMn9fAxc4r6cBqSKS4bxPFpE8EflcRDrwdTQ4at0ePt9UxukDdTQP1YryLbZKsL3tY/5GXQnxybZU1lZeD/znN5B6OEy4BfqPg/r9sOObjselQq+kABbfAQPPsn8HbZV+FFz6AtxSBP1OCn58USBYPR1uAsaLyEpgPLAN8Djr+htjRgM/AR4SkaMb7ywis51kl1dcXBykkJqWt3kP1fUebR9TrWtoHwtCIuueDsdfZOeOqi5v277Ln4QdX8PZf7bf0vuPs8u3fNLxuFRoeT0w/xd2AOnzHu5YyV672zcrkES2DfBvIMhxljUwxmw3xlxgjBkF/NFZVu48b3OeNwEfAqMaf4AxZo4xZrQxZnRWVmgTzNL1xSS4hB8cldH6xiq2bV0GST0he2hwjjdmlq0eWvVS4PtU7oT374GjzoBjp9llqYdBxjHaThYJPvsbFH0J5z4AaUeEO5qoFUgiWw4MFJEBIpIIXAYc1PtQRDJFxHesW4CnnOW9RSTJtw0wDvDvJNLpPlpfzOj+6aQkxfQwkyoQWz+3o3kEaxigI0fa0cqXP2Eb/wPx7m12ephzHzj423z/cfZGba+n+X3bqnwrLPwvqK8O3jFj2a58+OBeGDrFlsZVyLSayIwxbuB6YBHwHfCKMWaNiNwtIlOczSYA60RkPXAY4BuSeSiQJyJfYzuB3Neot2On2r23hrU7K7VaUbWuqszOM9aRbvdNGTvbdqve+H7r2276EL591TbwZx5z8Lr+46C2AnatDl5seU/b4bS+fS14x4xVnnr498/tEGWTH9RBo0MsoGKJMWYhsLDRstv9Xr8GHPLXb4z5DDi+gzEGzdINJQA6bYtqXeEX9jkY7WP+hk6x3eeXPwEDf9T8du5a+M9N9kbZpnqq5frayT6DI0YEJ7YN79rnLx+3U8/oxbf9lj5gB4y+9EVI0etNqMXUsBZL1xeT2SOJoYenhTsU1dVt+QziEqDPCcE9bnwijP4prF9kZ5puzmd/g9INtkqxqYk5e+ZAr36wOUgdPiq22dJd1lDY+a0dlku1z/aVsPT/wfDLYOjkcEcTE2ImkXmd2aBPH5hJXJx+01St2Pq5TWKhmN35xJn25ta8J5tev2ezvRAOnWJvpm5O/1Ntwm1qTL62Klhsn6c+aju4RNKI/V+/DM+eF9z2wvaqr7EjcfTIhnPuC3c0MSNmEtnq7RWU7a/T9jHVuvpq+6062O1jPmlHwtDzYMXzh450bgws/D2ICyb9T8vH6X+KHemjeG3HY1r/LvTsZ5P3qMshf77tMRkJNr4H3y+FgiXhjsQO+lv8HUx5BLr1Dnc0MSNmEplvWKpT9UZo1Zpt7ZhIs63GzoaacljdqGl57X9gwyI44xZbfdiShnayTzsWi7vWdiwZdJZtFxtzDXjd8FUQR+wPpYoi+5z3VHjjWPWSrRI+cWbL7Z8q6GIokZVwXJ80MnskhTsU1dU1TKQZwlEU+p8C2cfaKjxf1WDdfnj7D5A9zA5F1ZreAyD1SNjcwUS25VM7UsjAs+z7jKODO2J/qJUX2qra9YvsLQSdzRj4+H/tjc+5p8FZ97a+jwqqmEhklTX1rNi6R2eDVoHZ+jlkDWn7RJptIWInR9z57YEekh/9BfYWwY//F1wJgR2j/yk2EXWknWzDYjt8Vu5pB5aNnQ37dsLat9p/3M7gccPebXD8xfbn0dmlSK8X3rkZ3rsLjrsILn/NTqiqOlVMJLLPNpbi1tmgVSC8HptYQtU+5m/4JQc6Vuz+DpY9CiOvaNsknrnjYN8ue29ae61fZJOY/xBI/iP2d2X7doLx2GrggWfb+b46qxTproV5V8MX/7BTq1zwhO2VqjpdTCSypeuLSUl0cUI/bXxVrdidD7V7Q9s+5pOYYu/Xyn/DVksl9rCjnbeFb9zF9nbDL90IZRsPVCv6xLlsW9mWT2FnEG+6DrZyZzzzXn1h9NWwf3fnlCJrKuCFC2HNv2HiPXZU+5amZlEhFfU/eWMMSzcUc/LRmSTGR/3pqo4K5kDBgRjzM9uxYvtKm8TaevNs5iDontn+cRd9N0E31c1/1BW2ynF5Fy6VVTiJrGdfOOZM2/My1J0+KnfC0z+2banTHodxvwrt56lWRf2VfXNpFYVl1YzX0TxUILYusx0oevXrnM/LOBqGTbX3hI26qu37+7eTtceGd20yTB9w6Lru6bbt6ZtX7OzUXVFDIsuxpcgTZ9iu+CUbQvN5JQXw5ERblfuTl2HEZaH5HNUmUZ/IfN3utX1MtcoYOxBvRyfSbKuLn4UZb7a/air3VHtBb2uPvdp9tkqycbWiv7HtGLG/M5UXQvcMW00LdmbluHg7bmSwFX0FT51l7/2b+SYco13su4qYSGT9M7rTPyMl3KGorq6iECq3d161oo9Ix9pXGtrJ2lgq+34peOpaTmRHjIC+P7CdPgIdsb8zVRQefL9dj2x7s/mqF4M7iv+GxfDsZNuO+bN3oc+JwTu26rCoTmR1bi/LNpVqt3sVmC3O/WOd0WMxmLKHQXKvtlcvblgEiamtJ+6xs2DP94GN2N/ZKops+5i/0Vfbm83XzA/OZ6x6CV661M4B97PFtjpYdSlRncjytpRRVaezQasAbV1mp9047NhwR9I2cXFtbyczxpYyjp7Qepdx34j9XW38RWNs1WLj9szc0yBjYHA6fXz5hHOj86kw8z92UlPV5UR1Ilu6voT4OOHko3U2aBWAYE+k2Zn6n2I7IOzdEdj2u9bYG4kHnt36tr4R+ze827H71YKteo8dkaTxUF4itlRW9KW94by9tq2wNzsPPBsufxWSddaMrirKE1kxJ/bvTQ+dDVq1pqrMDvYaadWKPv3bOO5iS93um3LiT22CX97MiP3h4N/1vrERl9lbB9pbKqvdB/OusSXRaf+AeB3ariuL2kRWXFlL/o69Wq2oAuObf6uzO3oEy+HDbXtXWxLZESMg9fDAtk87wnaiWNnEiP3h4n8zdGPd0+HYC+ytA7WVbT/2O3+wpc8L5oR2qDIVFFGbyD7eYLvdj9dEpgKxdZmdSPPIIE+k2Vlc8dDvpMBujK7eY4fhaqm3YlPGzrYjWnz7avtiDLaWSmRgbzav22eTWVusfh1WvgCn/RYGnNb69irsojaRLV1fTEZKIsOO0HptFYCty+DIkQePNxhp+o+zc5PtL2l5u4L3wHgDax/z1+9kOOw42wEiGJN5dlRFEcR3s/eRNaXPiXD48faeskDjLd8Kb/7a7jvhluDFqkIqoEQmIpNEZJ2IFIjIzU2s7y8i74nINyLyoYjk+K2bISIbnMeMYAbfHK/X8PGGEk7T2aBVIOqrbcN+pLaP+TS0k7VSKtuw2F78+7Sx9OkbsX+X34j94VS+1VYrNnfzuq/Tx65voSiv9eN5PfD6bDsI8YX/DGwGAtUltJrIRMQFPAqcAwwDpovIsEabPQA8Z4wZDtwN/I+zbzpwB3ASMBa4Q0RCPnJv/o69lOps0CpQ21c6E2meEu5IOubIUbaE0lI7mdcDBYvtqBTt6Z15/MWQ3LNrdMVvfDN0U46/2N7EnBdAJ5WP/2pL5j/+K6QfFZwYVacIpEQ2FigwxmwyxtQBc4GpjbYZBvjulvzAb/3ZwGJjTJkxZg+wGJjU8bBb9pEzLNVpeiO0CkRnTKTZGeIToe+Ylkf42L4Sqkrb3j7mk5gCo660I/ZX7mzfMYKlvLD59jGfpFQYfqlt96oqa367rV/Ah/fZxDf80uDGqUIukETWByj0e1/kLPP3NXCB83oakCoiGQHui4jMFpE8EckrLi4ONPZm9c/ozuUn9SMrVbvMqgBs/RwyB0NKFNxv2P9U2LW6+UF+1y+ysykf/cP2f8boq+2I/V890/5jdFR9NVSVNN1jsbHRPwVPLXz9r6bX11TA69dAzz62NNaZ42yqoAhWZ4+bgPEishIYD2wDPIHubIyZY4wZbYwZnZXV8VLU5OFHcu+04zt8HBUDvF77bTzS28d8+p8CmAPT0TS24V3IGduxLuUZR8MxE+09Wu669h+nIyqK7HNrJTKwHT5yxtp4G3f6MAbe+i1UbIMLn7TVpiriBJLItgH+fy05zrIGxpjtxpgLjDGjgD86y8oD2VepsNqdD7UVkXv/WGM5o8GV2HQ7WeVO2LEKBrWzWtHf2Nl2Zuq1b3b8WO3hG+k/kEQGthRZWmAHSvb3zcuw+jWYcLMd1UVFpEAS2XJgoIgMEJFE4DJggf8GIpIpIr5j3QL4bqdfBJwlIr2dTh5nOcuU6hq2RuhAwc1J6AZ9RjfdTlawxD63t33M3zE/gh6Hw7q3O36s9vCVyAKpWgQ49nzo1vvgkT7KNsF/fmc7+Zz2u+DHqDpNq4nMGOMGrscmoO+AV4wxa0TkbhGZ4mw2AVgnIuuBw4B7nX3LgHuwyXA5cLezTKmuYevnkHoE9M4NdyTB0/8U2PH1oSNarF9kJw097LiOf0ZcnK2y272248dqj4pC29aXekRg2yd0g5GXw9q3oHIXeOrtEFTisqN3ROL4mqpBQIMQGmMWAgsbLbvd7/VrwGvN7PsUB0poSnUtWz/v/Ik0Qy13HHz8gL3Xyzf5o6ceNn4Ax10QvHPNHmKr6ryezk8E5YU2KbflXq8TfwrLHoGVzzn3Dn4FFz0deKlOdVlRO7KHUq0qL4S9RdHTPuaTM9aWNPxvjN66DOoqg1Ot6JM1xPYGLPs+eMcMVEVR2xNQ5jEwYDwsexQ+/l8YdYVN7CriaSJTscvXsy9a2sd8knrYm6P928k2vGvHkjxqQvA+J2uofS7+LnjHDFTF1tZvhm7K6KvtrQnpR8GkvwQ/LhUWmshU7O8UxqwAACAASURBVNr6mR0xPjvCJtIMRP9TbNWZb6T6DYttlWNSj+B9RtZg+1zcye1kXg/s3R54j0V/Q34Mp/8XXPZicH8WKqw0kanYtfVzOxKGKwrnq8s91Q67tS0P9myxyaatgwS3JqkH9OzX+R0+KnfaG7Lb07blSoAf3gbZQ4MflwqbKPwPVqoVO76xY+/tzrdzVkWjfj8AxFYvpqyzy4LZPuaTPaTzS2StTd+iYo4mMtV1GQP7i+39Px0diby+Gtb8285wvC3Pzh488go4aXZwYu1qknva7vFbPrVdz9OPsp0dgi1rCGz6EDzuzivZlmsiUwfTRKbCz+u1vQeL19lv98VroXi9fV9bAQkpdtSF3HF2LME+JwQ+9XzpRnsT7KoXbSN/xkCYdB+MuMwmyGiWe+qBG4BPnBmaz8geCp462PM9ZA4MzWc01lAia0dnDxWVNJGpzuWug43v255uDYlrPdTvP7BNSrbtSDD8Ykg/2l4kN38K7//Jro9Phpwxdv6t3HH2dUK3A/t76mHdQlv6+v4jiIuHIZPtjMG5p0XXPWMt6X8KfP53+zoU1YpwoMPH7u86N5F1662dNVQDTWSqcy1/Ahbdal+nHmkvhCdcZZ+zhtjn5ga0rSqz90Zt+RQ2fwIf/QU+MnZswT4n2sQmAiueh307bdXTD2+z046kHt5559hV+OZXS+h+YNLNYMv077k4pcVNgyaQ6VtUTNFEpjrX7nxIyYIbvmr7SOPd02HoZPsAqC63o1ds/sQmt08eBOO1o1mMeciWQmJ56KGUDJvge/WHhOTQfEZSD+jVr3M7fFQU2RH4lXJoIlOdq3QjZA4KznQZ3XrBoLPtA+zYgvXV0CO748eOFle9YatWQylraOd1wTfGVi0eNb5zPk9FBL2PTHWukg2h+zadlKpJrLGk1IPbD0MhewiUbrA9F0Oteg/U7dOqRXUQTWSq81TvsbP6ZoSgG7gKnyyn52LZptB/Vlunb1ExQROZ6jylzoUuo5N6t6nO0TBUVSeMuahd71UTNJGpzlNaYJ+1RBZdGrrgd0I7WcPN0P1C/1kqYmgiU52ntMBOhhhNk1gqSEyxPSM7o+diRaG9jzAlM/SfpSKGJjLVeUoL7AUvPjHckahgyx7aeYmsZ07s3NSuAqKJTHWe0gKtVoxWWUNsj1RPfWg/R2+GVk3QRKY6hzH2HjJNZNEpe6idNibUPRfbMzO0inoBJTIRmSQi60SkQERubmJ9PxH5QERWisg3InKuszxXRKpFZJXz+EewT0BFiModdjzFUIzArsIva4h93h3Cnov1NbB/t5bI1CFaveVfRFzAo8BEoAhYLiILjDH5fpvdBrxijHlMRIYBC4FcZ91GY8zI4IatIo72WIxumYMACW07me8eMk1kqpFASmRjgQJjzCZjTB0wF5jaaBsDpDmvewLbgxeiigqayKJbYnfo3T+0JTLfPWRatagaCSSR9QEK/d4XOcv83QlcISJF2NLYDX7rBjhVjh+JyGlNfYCIzBaRPBHJKy4uDjx6FTlKN0J8NzvivYpOWUPt1DyhojdDq2YEq7PHdOAZY0wOcC7wvIjEATuAfsaYUcBvgZdEJK3xzsaYOcaY0caY0VlZWUEKSXUppQV2jMU47V8UtbKH2N9zqHoulhfa+xDTGn+PVrEukKvKNsC/LJ/jLPP3M+AVAGPMMiAZyDTG1BpjSp3lXwEbgUEdDVpFIF8iU9Ery+m5WLoxNMevKILUI8CVEJrjq4gVSCJbDgwUkQEikghcBixotM1W4EwAERmKTWTFIpLldBZBRI4CBgKdMLKo6lI89bBns7aPRbtsp+diqMZc9N0MrVQjrSYyY4wbuB5YBHyH7Z24RkTuFhHflLC/A2aJyNfAv4CZxhgDnA58IyKrgNeAa40xZaE4EdWF7dkCXrcOFhztMgYCEroxF8u3ao9F1aSAZtwzxizEduLwX3a73+t84JC51I0x84B5HYxRRTrtsRgbErvbcTRDUSLzemDvdu2xqJqkLe8q9BoSmbaRRb3sEM0WvW+XbX/TqkXVBE1kKvRKC6BbOnRPD3ckKtSyhkDZRnDXBfe4On2LaoEmMhV6Olhw7MgeattDy4Lcc1FvhlYt0ESmQk8TWewI1ZiLejO0aoEmMhVatfvsgME6WHBsyBxob1oO9piL5YWQ3AuSUoN7XBUVNJGp0PJVMWmJLDYkdLM9F4NeItPpW1TzNJGp0NKu97EnKwSzRVfohJqqeZrIVGj5hitKPyq8cajOkz3E/t6D1XPRGJ0ZWrVIE5kKrdICewFK6BbuSFRnyRoKxnOgNN5RNeVQV6lVi6pZmshUaOlgwbEn2GMuNkyoqT0WVdM0kanQMQZKtOt9zMlwei4Ga4QPvRlatUITmQqd/SVQW6GDBceahGToPSCIJTK9GVq1TBOZCh3tsRi7gjnmYkUhuJKge2ZwjqeijiYyFTo6WHDsyhoCZZvAXdvxY5U785Dp7OKqGfqXoUKntADiEqCXtm3EnOwg9lysKNRqRdUiTWQqdEoL7P1jca5wR6I6WzDHXKwo0h6LqkWayFTo6GDBsStYYy7W19i5yLTHomqBJjIVGl6PbSPR9rHYFJ9kS+MdLZHt3WaftWpRtSCgRCYik0RknYgUiMjNTazvJyIfiMhKEflGRM71W3eLs986ETk7mMGrLqyiEDx19pu5ik1ZQzpeItPpW1QAWk1kIuICHgXOAYYB00VkWKPNbgNeMcaMAi4D/u7sO8x5fywwCfi7czwV7bTrvcoeakvl9TXtP0bDzdBaIlPNC6RENhYoMMZsMsbUAXOBqY22MUCa87onsN15PRWYa4ypNcZ8DxQ4x1PRrlSnb4l5WUPAeKF0Q/uPUVEICKT1CVpYKvoEksj6AIV+74ucZf7uBK4QkSJgIXBDG/ZFRGaLSJ6I5BUXFwcYuurSSgsgKQ1SssIdiQqX7KH2uXhd+49RUQSph0N8YnBiUlEpWJ09pgPPGGNygHOB50Uk4GMbY+YYY0YbY0ZnZemFLyr4BgsWCXckKlwyjgFxdazDR/lWrVZUrQok2WwD/P+Scpxl/n4GvAJgjFkGJAOZAe6ropEOFqzik+yXmY50+NCboVUAAklky4GBIjJARBKxnTcWNNpmK3AmgIgMxSayYme7y0QkSUQGAAOBL4MVvOqi6qvtBUgHC1ZZg9tfIvN6oWKb9lhUrWo1kRlj3MD1wCLgO2zvxDUicreITHE2+x0wS0S+Bv4FzDTWGmxJLR94B/ilMcYTihNRXUjZ94DRe8iUnWRzz/ft67m4bxd467VqUbUqPpCNjDELsZ04/Jfd7vc6HxjXzL73Avd2IEYVabTrvfLJdnoulqyHI4a3bd+G6Vt0VA/VMh3ZQwWfjnqvfLI60HNRb4ZWAdJEpoKvdCP0OBySUsMdiQq3jGMgLr59k2zqzdAqQJrIVPCVbtBqRWXFJ0L60e2bZLOiEJJ7QnJa69uqmKaJTAWf7x4ypcD2XGxPiayiSEtjKiCayFRwVZVBVakOFqwOyB5qe7LWV7dtv/JCTWQqIJrIVHCVbbLPWrWofLKGAMb2XGwLvRlaBUgTmQou7XqvGvONudiWdrKaCqjdqz0WVUA0kangKi2w4+v16h/uSFRXkX6003OxDYlMeyyqNtBEpoKrtAB699fRytUB8Ym2hN6WRKY3Q6s20ESmgksHC1ZNyRrStjEXK4rss1YtqgBoIlPB4/VC2UYdLFgdKnuYHXPx+Wnw1TOwv6Tl7cu3gisRUrI7JTwV2QIaa1GpgFTugPoqvYdMHWrMNfZvI/8NePNGeOs30H8cDJsKQ8+zk2f6qyi0pbE4/a6tWqd/JSp4tMeiak5KBky8C361Eq79BE77nR3dfuFN8Nch8NQ58PljB6oUK4q0WlEFTEtkKng0kanWiMDhx9vHD2+zXfLz37CPd262j5wxdvmwqeGOVkUITWQqeEo3QkJ3SD0i3JGoSJE9xD4m/AFKNhxIanWVcNix4Y5ORQhNZCp4Sjc49wxpjbVqh8yBcPpN9rG/BLr1DndEKkLoFUcFjw4WrIIlJRPiXOGOQkUITWQqONx1sGeLDhaslOp0mshUcJRvAePRjh5KqU4XUCITkUkisk5ECkTk5ibWPygiq5zHehEp91vn8Vu3IJjBqy5EeywqpcKk1c4eIuICHgUmAkXAchFZYIzJ921jjPmN3/Y3AKP8DlFtjBkZvJBVl+RLZOlHhTcOpVTMCaRENhYoMMZsMsbUAXOBlm7wmA78KxjBqQhSWgDdM6B7ergjUUrFmEASWR+g0O99kbPsECLSHxgAvO+3OFlE8kTkcxE5v5n9Zjvb5BUXFwcYuupSdLBgpVSYBLuzx2XAa8YYj9+y/saY0cBPgIdE5JD+2caYOcaY0caY0VlZWUEOSXWK0gIdLFgpFRaBJLJtgP/sdjnOsqZcRqNqRWPMNud5E/AhB7efqWhQWwn7duo9ZEqpsAgkkS0HBorIABFJxCarQ3ofisgQoDewzG9ZbxFJcl5nAuOA/Mb7qghXutE+a9WiUioMWu21aIxxi8j1wCLABTxljFkjIncDecYYX1K7DJhrjDF+uw8FHhcRLzZp3uff21FFCe16r5QKo4DGWjTGLAQWNlp2e6P3dzax32fA8R2IT0WC0o2AQPqAcEeilIpBOrKH6rjSDdCzLyR0C3ckSqkYpKPfq/arr7FJbMc32tFDKRU2mshU6+r2Q8l6KF4HxWsPPO/ZDMZrtxk6OawhKqVilyYydaiqMvjsYdi1xias8q0H1sUl2E4dhw+H4y+GrMGQORiyh4UvXqVUTNNEpg5mDPz7WihYAocNg74nwairbMLKGmI7dLgSwh2lUko10ESmDrbyBdiwCCb9BX5wbbijUUqpVmmvRXVA+VZ45xbIPQ3Gzg53NEopFRBNZMryeuGNXwIGpj4KcfqnoZSKDFq1qKy8J+H7pXDe/0Hv/uGORimlAqZfu5UdmWPx7XDMj+CEGeGORiml2kQTWazzemD+L2xPxCl/A5FwR6SUUm2iVYuxbtkjUPgFTJsDaUeGOxqllGozLZHFst3fwft/giGTYfgl4Y5GKaXaRRNZrPLU2xufk1Jh8kNapaiUilhatRirPv5f2LEKLnkeemSFOxqllGo3LZHFou2rYOn9dqzEYVPCHY1SSnWIJrJY4661VYrdM+Gc+8MdjVJKdZhWLcaaD/8Hir+Dn7wK3dPDHY1SSnVYQCUyEZkkIutEpEBEbm5i/YMissp5rBeRcr91M0Rkg/PQu23DqfBL+PT/4ISrYNBZ4Y5GKaWCotUSmYi4gEeBiUARsFxEFhhj8n3bGGN+47f9DcAo53U6cAcwGjDAV86+e4J6Fqp1dVW2SjGtD5x1b7ijUUqpoAmkRDYWKDDGbDLG1AFzgaktbD8d+Jfz+mxgsTGmzElei4FJHQlYtdOSO6Bsox0QODkt3NEopVTQBJLI+gCFfu+LnGWHEJH+wADg/bbsKyKzRSRPRPKKi4sDiVu1xddz4cs58IPr4Kjx4Y5GKaWCKti9Fi8DXjPGeNqykzFmjjFmtDFmdFaW3tMUVNu+ggW/snOMTbw73NEopVTQBZLItgF9/d7nOMuachkHqhXbuq8KtsqdMPdySD0MLn7WDgyslFJRJpBEthwYKCIDRCQRm6wWNN5IRIYAvYFlfosXAWeJSG8R6Q2c5SxToeauhZevgJoKuOxfkJIR7oiUUiokWu21aIxxi8j12ATkAp4yxqwRkbuBPGOML6ldBsw1xhi/fctE5B5sMgS42xhTFtxTUIcwBt76LRQth0ueg8OPC3dESikVMuKXd7qE0aNHm7y8vHCHEdk+/we88wcY/wc449ZwR6NUs+rr6ykqKqKmpibcoaguIjk5mZycHBISDm4KEZGvjDGjm9pHR/aINps+hEW32qlZxh9y77pSXUpRURGpqank5uYiOgNDzDPGUFpaSlFREQMGDAh4Px1rMZqUbYJXZkDmIJj2D4jTX6/q2mpqasjIyNAkpgAQETIyMtpcQtcrXbSorYR//cTOKzb9JTvPmFIRQJOY8teevwetWowGXq8dfqpkPVz5OqQfFe6IlFKq02iJLBp8dB+sfQvO/jMcNSHc0SgVMUpLSxk5ciQjR47k8MMPp0+fPg3v6+rqAFiwYAH33Xdfi8fZvn07F110UWeErJqgvRYjXf4b8MpVMPIKmPqIrVpUKkJ89913DB06NNxhAHDnnXfSo0cPbrrppoZlbreb+PjorbjyeDy4XK5wh3GIpv4utNditNq52lYp5oyByf+rSUxFtLveXEP+9r1BPeawI9O447xj27TPzJkzSU5OZuXKlYwbN47hw4eTl5fHI488wsyZM0lLSyMvL4+dO3dy//33c9FFF7F582YmT57M6tWreeaZZ1iwYAFVVVVs3LiRadOmcf/9dhLbJ598kr/85S/06tWLESNGkJSUxCOPPHLQ53/55ZfceOON1NTU0K1bN55++mkGDx6Mx+PhD3/4A++88w5xcXHMmjWLG264geXLl3PjjTeyf/9+kpKSeO+995g3b15DzACTJ0/mpptuYsKECfTo0YOf//znLFmyhEcffZT333+fN998k+rqak455RQef/xxRISCggKuvfZaiouLcblcvPrqq9x1111ccMEFnH/++QBcfvnlXHLJJUyd2tI48qGniSxS7dsNc6dDci+49AWITwp3REpFjaKiIj777DNcLhfPPPPMQet27NjBJ598wtq1a5kyZUqTVYqrVq1i5cqVJCUlMXjwYG644QZcLhf33HMPK1asIDU1lR/+8IeMGDHikH2HDBnCxx9/THx8PEuWLOHWW29l3rx5zJkzh82bN7Nq1Sri4+MpKyujrq6OSy+9lJdffpkxY8awd+9eunXr1uK57d+/n5NOOom//vWvAAwbNozbb78dgCuvvJK33nqL8847j8svv5ybb76ZadOmUVNTg9fr5Wc/+xkPPvgg559/PhUVFXz22Wc8++yz7fwpB48mskhUuROePQ/2l8DMtyD18HBHpFSHtbXkFEoXX3xxs1Vu559/PnFxcQwbNoxdu3Y1uc2ZZ55Jz549AZsotmzZQklJCePHjyc9Pb3hM9avX3/IvhUVFcyYMYMNGzYgItTX1wOwZMkSrr322oaqzvT0dL799luOOOIIxowZA0BaWutTNLlcLi688MKG9x988AH3338/VVVVlJWVceyxxzJhwgS2bdvGtGnTAHuTMsD48eO57rrrKC4uZt68eVx44YVdoupVO3tEmr3b4ZkfQ8U2uPw16HNiuCNSKuqkpKQ0uy4p6UDtR3N9DPy3cblcuN3ugD/7v//7vznjjDNYvXo1b775ZrtGPYmPj8fr9Ta89z9GcnJyQ5Kuqanhuuuu47XXXuPbb79l1qxZrX7eVVddxQsvvMDTTz/N1Vdf3ebYQkETWSSpKIKnz4XKXbabfe64cEeklArQmDFj+Oijj9izZw9ut5t58+Y1uV1FRQV9+thpG/2rNSdOnMjjjz/ekBTLysoYPHgwO3bsYPlyO5xtZWUlbreb3NxcVq1ahdfrpbCwkC+//LLJz/IlrczMTPbt28drr70GQGpqKjk5OcyfPx+A2tpaqqqqANuG+NBDDwG2tNkVaCKLFHu22CRWVQpX/hv6/SDcESml2qBPnz7ceuutjB07lnHjxpGbm9tQ/ejv97//PbfccgujRo06qCR3zTXX0K9fP4YPH86IESN46aWXSExM5OWXX+aGG25gxIgRTJw4kZqaGsaNG8eAAQMYNmwYv/rVrzjhhBOajKlXr17MmjWL4447jrPPPruhihLg+eef5+GHH2b48OGccsop7Ny5E4DDDjuMoUOH8tOf/jTIP6H20+73kaDse9smVrsXrpwPfZr+o1Qq0nSl7vedYd++ffTo0QO32820adO4+uqrG9qhIkVVVRXHH388K1asaDIRB0Nbu99riayrK91o28Tq9sFVCzSJKRXB7rzzTkaOHMlxxx3HgAEDGrqxR4olS5YwdOhQbrjhhpAlsfYIf3cT1bySDfDMZPDWw4w34fDjwx2RUqoDHnjggXCH0CE/+tGP2LJlS7jDOIQmsq5q91pbnYiBGW/BYV2jUVUppboaTWRd0a58m8TiXDaJZQ0Od0RKKdVlaRtZV7PzW9sm5kqAmf/RJKaUUq3QRNZVGAPfL7UlsYRuNollDgx3VEop1eUFlMhEZJKIrBORAhG5uZltLhGRfBFZIyIv+S33iMgq57EgWIFHBa8XCr+ERX+Eh4bbJJbYwyaxjKPDHZ1SUe+MM85g0aJFBy176KGH+MUvftHsPhMmTMB3i9C5555LeXn5IdvceeedrXbsmD9/Pvn5+Q3vb7/9dpYsWdKW8JWj1TYyEXEBjwITgSJguYgsMMbk+20zELgFGGeM2SMi2X6HqDbGjAxy3JHL64HCL+z0K/kLoHI7uBLhqDNgws0wdDIkd51urUpFs+nTpzN37lzOPvvshmVz585tGK2+NQsXLmz3Z8+fP5/Jkyc3jI5x9913t/tY4dJVpoEJpLPHWKDAGLMJQETmAlOBfL9tZgGPGmP2ABhjdgc70IjmccOWT23yWvsW7NsFriQYOBGG3QWDztbkpdTbN9s24mA6/Hg4p/lJMS+66CJuu+026urqSExMZPPmzWzfvp3TTjuNX/ziFyxfvpzq6mouuugi7rrrrkP2z83NJS8vj8zMTO69916effZZsrOz6du3LyeeaMdBfeKJJ5gzZw51dXUcc8wxPP/886xatYoFCxbw0Ucf8ac//Yl58+Zxzz33MHnyZC666CLee+89brrpJtxuN2PGjOGxxx4jKSmJ3NxcZsyYwZtvvkl9fT2vvvoqQ4YMOSimzZs3c+WVV7J//34AHnnkEU455RQA/vKXv/DCCy8QFxfHOeecw3333dfkdC2FhYU88MADvPXWWwBcf/31jB49mpkzZ5Kbm8ull17K4sWL+f3vf09lZeUh59e9e3d27drFtddey6ZNmwB47LHHeOedd0hPT+fXv/41AH/84x/Jzs7mxhtv7NCvOZBE1gco9HtfBJzUaJtBACLyKeAC7jTGvOOsSxaRPMAN3GeMmd/4A0RkNjAboF+/fm06gQ7xemDrMihYAt16Q9YQ27miZz+Ia2fzoTF2ipWSdVC8DnasgnVv26GlErrDwLNg2BT7nJQa3PNRSrVJeno6Y8eO5e2332bq1KnMnTuXSy65BBHh3nvvJT09HY/Hw5lnnsk333zD8OHDmzzOV199xdy5c1m1ahVut5sTTjihIZFdcMEFzJo1C4DbbruNJ598khtuuIEpU6Y0JC5/NTU1zJw5k/fee49BgwZx1VVX8dhjjzVc/DMzM1mxYgV///vfeeCBB/jnP/950P7Z2dksXryY5ORkNmzYwPTp08nLy+Ptt9/mjTfe4IsvvqB79+6UlZUBNDldS2FhIS3JyMhgxYoVgJ1lu6nz+9WvfsX48eP597//jcfjYd++fRx55JFccMEF/PrXv8br9TJ37txmx4Fsi2B1v48HBgITgBxgqYgcb4wpB/obY7aJyFHA+yLyrTFmo//Oxpg5wBywQ1QFKaamedyw+eMDpaP9xSAuMB6/s+lmO1r4ElvWEPvonQuueF/QsHebTVbF66B47YHnGr868+SecMxEGDYVjvkRJHYP6ekpFbFaKDmFkq960ZfInnzySQBeeeUV5syZg9vtZseOHeTn5zebyD7++GOmTZtG9+72/3vKlCkN61avXs1tt91GeXk5+/btO6gasynr1q1jwIABDBo0CIAZM2bw6KOPNiSyCy64AIATTzyR119//ZD96+vruf7661m1ahUul6thqpglS5bw05/+tCHG9PR0Kisrm5yupTWXXnppq+f3/vvv89xzzwF2BoCePXvSs2dPMjIyWLlyJbt27WLUqFFkZGQE9JktCSSRbQP6+r3PcZb5KwK+MMbUA9+LyHpsYltujNkGYIzZJCIfAqOAjXQmd53tEZg/H9b+B6rL/EpHU+2ztx6K1x+ckLZ8Bt++cuA4rkTIGGgnsSzZAHWVB9Z1S4fsoXDcBQcnwB6H6czNSnVhU6dO5Te/+Q0rVqygqqqKE088ke+//54HHniA5cuX07t3b2bOnNmu6VTAjhY/f/58RowYwTPPPMOHH37YoXh9U8Q0Nz3Mgw8+yGGHHcbXX3+N1+sNODn5a2kaGDh4mpu2nt8111zDM888w86dO4M2DUwgiWw5MFBEBmAT2GXATxptMx+YDjwtIpnYqsZNItIbqDLG1DrLxwGBtaJ2VH0NbPrAlrzWLYSaCkhMhcGTbPI6+sxDS0f9TrIPf7WVULL+QHLbvRbcNTDyJ5A16EBpLSWzU05LKRVcPXr04IwzzuDqq69m+vTpAOzdu5eUlBR69uzJrl27ePvtt5kwYUKzxzj99NOZOXMmt9xyC263mzfffJOf//zngJ1a5YgjjqC+vp4XX3yxYYqW1NRUKisrDznW4MGD2bx5MwUFBQ1tTuPHjw/4fCoqKsjJySEuLo5nn30Wj8fWNk2cOJG7776byy+/vKFqMT09vWG6lvPPP5/a2lo8Hg/9+/cnPz+f2tpaqquree+99zj11FOb/Lzmzu/MM89sqBL1VS327NmTadOmcfvtt1NfX89LL73U5DHbqtVEZoxxi8j1wCJs+9dTxpg1InI3kGeMWeCsO0tE8gEP8F/GmFIROQV4XES82K7+9/n3dgyZTx6CpQ/YElNyTxj8Y9suddQZkNDGbydJqXbySp3AUqmoNX36dKZNm8bcuXMBGDFiBKNGjWLIkCH07duXceNanvvvhBNO4NJLL2XEiBFkZ2cfNB3KPffcw0knnURWVhYnnXRSQ/K67LLLmDVrFg8//HDDPGBgq/eefvppLr744obOHtdee23A53Lddddx4YUX8txzzzFp0qSG0tOkSZNYXcA5JQAABTpJREFUtWoVo0ePJjExkXPPPZc///nPPP/88/z85z/n9ttvJyEhgVdffZWjjjqKSy65pGFw41GjRjX7ec2d3//93/8xe/ZsnnzySVwuF4899hgnn3wyiYmJnHHGGfTq1StoPR6jcxqXb1+DTR/CsPNhwOkQnxiU2JRSwRVr07go8Hq9nHDCCbz66qsMHNj0oA9tncYlOsdaPP4i+1BKKdVl5OfnM3nyZKZNm9ZsEmuP6ExkSimlupxhw4Y13FcWTDrWolIqrLpa84YKr/b8PWgiU0qFTXJyMqWlpZrMFGCTWGlpaZtvGdCqRaVU2OTk5FBUVERxcXG4Q1FdRHJyMjk5OW3aRxOZUipsEhISGDBgQLjDUBFOqxaVUkpFNE1kSimlIpomMqWUUhGty43sISLFwJYgHCoTKAnCcbqyWDhHiI3z1HOMHrFwnuE4x/7GmKymVnS5RBYsIpLX3HAm0SIWzhFi4zz1HKNHLJxnVztHrVpUSikV0TSRKaWUimjRnMjmhDuAThAL5wixcZ56jtEjFs6zS51j1LaRKaWUig3RXCJTSikVAzSRKaWUimhRmchEZJKIrBORAhG5OdzxhIKIbBaRb0VklYh0cErtrkNEnhKR3SKy2m9ZuogsFpENznPvcMbYUc2c450iss35fa4SkXPDGWNHiUhfEflARPJFZI2I3Ogsj5rfZQvnGDW/SxFJFpEvReRr5xzvcpYPEJEvnGvsyyKSGNY4o62NTERcwHpgIlAELAemG2PywxpYkInIZmC0MSaqbrwUkdOBfcBzxpjjnGX3A2XGmPucLya9jTF/CGecHdHMOd4J7DPGPBDO2IJFRI4AjjDGrBCRVOAr4HxgJlHyu2zhHC8hSn6XIiJAijFmn4gkAJ8ANwK/BV43xswVkX8AXxtjHgtXnNFYIhsLFBhjNhlj6oC5wNQwx6QCZIxZCpQ1WjwVeNZ5/Sz2YhGxmjnHqGKM2WGMWeG8rgS+A/oQRb/LFs4xahhrn/M2wXkY4IfAa87ysP8eozGR9QEK/d4XEWV/XA4DvCsiX4nI7HAHE2KHGWN2OK93AoeFM5gQul5EvnGqHiO2yq0xEckFRgFfEKW/y0bnCFH0uxQRl4isAnYDi4GNQLkxxu1sEvZrbDQmslhxqjHmBOAc4JdOdVXUM7YuPLrqw63HgKOBkcAO4K/hDSc4RKQHMA/4tTFmr/+6aPldNnGOUfW7NMZ4jDEjgRxsjdeQMId0iGhMZNuAvn7vc5xlUcUYs8153g38G/sHFq12Oe0RvnaJ3WGOJ+iMMbucC4YXeIIo+H06bSrzgBeNMa87i6Pqd9nUOUbj7xLAGFMOfACcDPQSEd/EzGG/xkZjIlsODHR61SQClwELwhxTUIlIitO4jIikAGcBq1veK6ItAGY4r2f8//buGKWhIAjA8D/Exk4EW4scwBNY5AqCBAL23sEmINiKF9BSJZWeIQdIYZHW1iPYOBa7QppYKY/d/F/1eO8VOwzssLsDC7wOOJZ/8TO5V2c0ns/aJHAPrDPzduNTN7ncFmNPuYyIo4g4qM/7lCa6NaWgndffBs9jd12LALXd9Q4YAQ+ZeTPwkP5URIwpqzCAPeCxlxgj4gmYUK6J+ADmwAuwAI4pV/xMM7PZZoktMU4oW1EJvAOXG2dJzYmIU2AJvAFf9fUV5Qypi1z+EuOMTnIZESeUZo4RZeGzyMzrOgc9A4fACrjIzM/BxtljIZMk7Y4etxYlSTvEQiZJapqFTJLUNAuZJKlpFjJJUtMsZJKkplnIJElN+wbGSS9GaOgpqQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### for f1 score and other values import files ###\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#importing packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "### matrics\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "rJ9xjnoVFZKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####predictions on test set\n",
        "\n",
        "y_test=[]\n",
        "probaa=[]\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "model.load_weights(r\"/content/drive/MyDrive/rhd_model/h5/mobilenetv2_SE_.h5\")\n",
        "\n",
        "\n",
        "cls=5  #nummber of classes\n",
        "\n",
        "## give directory of class serially..if less than 4 classes comment out the last unused dir_path\n",
        "dir_path1=r'/content/drive/MyDrive/rhd_model/Furier_transform/Normal'\n",
        "dir_path2=r'/content/drive/MyDrive/rhd_model/Furier_transform/Tuberculosis'\n",
        "dir_path3=r'/content/drive/MyDrive/rhd_model/Furier_transform/covid19'\n",
        "dir_path4=r'/content/drive/MyDrive/rhd_model/Furier_transform/pneumonia'\n",
        "#dir_path5=r'D:\\Inam Ullah Khan\\Dataset split\\val\\Viral Pneumonia'\n",
        "\n",
        "\n",
        "\n",
        "w1=0\n",
        "w2=0\n",
        "w3=0\n",
        "w4=0\n",
        "\n",
        "\n",
        "if cls==5:\n",
        "  for filename in os.listdir(dir_path1):\n",
        "      img=image.load_img(dir_path1+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(0)\n",
        "      w1+=1\n",
        "      print(w1,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path2):\n",
        "      img=image.load_img(dir_path2+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(1)\n",
        "      #if res!=1: a2+=1\n",
        "      w2+=1\n",
        "      print(w2,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path3):\n",
        "      img=image.load_img(dir_path3+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(2)\n",
        "      w3+=1\n",
        "      print(w3,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path4):\n",
        "      img=image.load_img(dir_path4+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(3)\n",
        "      w4+=1\n",
        "      print(w4,end='_')\n",
        "\n",
        "\n",
        "  print('class numbers', cls)\n",
        "  print('prediction number:',len(probaa))\n",
        "  print('true labels:',len(y_test))\n",
        "\n",
        "if cls==4:\n",
        "  for filename in os.listdir(dir_path1):\n",
        "      img=image.load_img(dir_path1+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(0)\n",
        "      w1+=1\n",
        "      print(w1,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path2):\n",
        "      img=image.load_img(dir_path2+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(1)\n",
        "      #if res!=1: a2+=1\n",
        "      w2+=1\n",
        "      print(w2,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path3):\n",
        "      img=image.load_img(dir_path3+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(2)\n",
        "      w3+=1\n",
        "      print(w3,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path4):\n",
        "      img=image.load_img(dir_path4+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(3)\n",
        "      w4+=1\n",
        "      print(w4,end='_')\n",
        "\n",
        "  print('class numbers', cls)\n",
        "  print('prediction number:',len(probaa))\n",
        "  print('true labels:',len(y_test))\n",
        "\n",
        "\n",
        "if cls==2:\n",
        "  for filename in os.listdir(dir_path1):\n",
        "      img=image.load_img(dir_path1+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(0)\n",
        "      w1+=1\n",
        "      print(w1,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path2):\n",
        "      img=image.load_img(dir_path2+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(1)\n",
        "      #if res!=1: a2+=1\n",
        "      w2+=1\n",
        "      print(w2,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print('class numbers', cls)\n",
        "  print('prediction number:',len(probaa))\n",
        "  print('true labels:',len(y_test))\n",
        "\n",
        "\n",
        "if cls==3:\n",
        "  for filename in os.listdir(dir_path1):\n",
        "      img=image.load_img(dir_path1+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(0)\n",
        "      w1+=1\n",
        "      print(w1,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path2):\n",
        "      img=image.load_img(dir_path2+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(1)\n",
        "      w2+=1\n",
        "      print(w2,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path3):\n",
        "      img=image.load_img(dir_path3+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(2)\n",
        "      w3+=1\n",
        "      print(w3,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print('class numbers', cls)\n",
        "  print('prediction number:',len(probaa))\n",
        "  print('true labels:',len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PziSNaZrFkOc",
        "outputId": "36e5ffe4-cb47-4083-ec81-ebf9287a9030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_2_3_4_5_6_7_8_9_10_11_12_13_14_15_16_17_18_19_20_21_22_23_24_25_26_27_28_29_30_31_32_33_34_35_36_37_38_39_40_41_42_43_44_45_46_47_48_49_50_51_52_53_54_55_56_57_58_59_60_61_62_63_64_65_66_67_68_69_70_71_72_73_74_75_76_77_78_79_80_81_82_83_84_85_86_87_88_89_90_91_92_93_94_95_96_97_98_99_100_101_102_103_104_105_106_107_108_109_110_111_112_113_114_115_116_117_118_119_120_121_122_123_124_125_126_127_128_129_130_131_132_133_134_135_136_137_138_139_140_141_142_143_144_145_146_147_148_149_150_151_152_153_154_155_156_157_158_159_160_161_162_163_164_165_166_167_168_169_170_171_172_173_174_175_176_177_178_179_180_181_182_183_184_185_186_187_188_189_190_191_192_193_194_195_196_197_198_199_200_201_202_203_204_205_206_207_208_209_210_211_212_213_214_215_216_217_218_219_220_221_222_223_224_225_226_227_228_229_230_231_232_233_234_235_236_237_238_239_240_241_242_243_244_245_246_247_248_249_250_251_252_253_254_255_256_257_258_259_260_261_262_263_264_265_266_267_268_269_270_271_272_273_274_275_276_277_278_279_280_281_282_283_284_285_286_287_288_289_290_291_292_293_294_295_296_297_298_299_300_301_302_303_304_305_306_307_308_309_310_311_312_313_314_315_316_317_318_319_320_321_322_323_324_325_326_327_328_329_330_331_332_333_334_335_336_337_338_339_340_341_342_343_344_345_346_347_348_349_350_351_352_353_354_355_356_357_358_359_360_361_362_363_364_365_366_367_368_369_370_371_372_373_374_375_376_377_378_379_380_381_382_383_384_385_386_387_388_389_390_391_392_393_394_395_396_397_398_399_400_401_402_403_404_405_406_407_408_409_410_411_412_413_414_415_416_417_418_419_420_421_422_423_424_425_426_427_428_429_430_431_432_433_434_435_436_437_438_439_440_441_442_443_444_445_446_447_448_449_450_451_452_453_454_455_456_457_458_459_460_461_462_463_464_465_466_467_468_469_470_471_472_473_474_475_476_477_478_479_480_481_482_483_484_485_486_487_488_489_490_491_492_493_494_495_496_497_498_499_500_501_502_503_504_505_506_507_508_509_510_511_512_513_514_515_516_517_518_519_520_521_522_523_524_525_526_527_528_529_530_531_532_533_534_535_536_537_538_539_540_541_542_543_544_545_546_547_548_549_550_551_552_553_554_555_556_557_558_559_560_561_562_563_564_565_566_567_568_569_570_571_572_573_574_575_576_577_578_579_580_581_582_583_584_585_586_587_588_589_590_591_592_593_594_595_596_597_598_599_600_601_602_603_604_605_606_607_608_609_610_611_612_613_614_615_616_617_618_619_620_621_622_623_624_625_626_627_628_629_630_631_632_633_634_635_636_637_638_639_640_641_642_643_644_645_646_647_648_649_650_651_652_653_654_655_656_657_658_659_660_661_662_663_664_665_666_667_668_669_670_671_672_673_674_675_676_677_678_679_680_681_682_683_684_685_686_687_688_689_690_691_692_693_694_695_696_697_698_699_700_701_702_703_704_705_706_707_708_709_710_711_712_713_714_715_716_717_718_719_720_721_722_723_724_725_726_727_728_729_730_731_732_733_734_735_736_737_738_739_740_741_742_743_744_745_746_747_748_749_750_751_752_753_754_755_756_757_758_759_760_761_762_763_764_765_766_767_768_769_770_771_772_773_774_775_776_777_778_779_780_781_782_783_784_785_786_787_788_789_790_791_792_793_794_795_796_797_798_799_800_801_802_803_804_805_806_807_808_809_810_811_812_813_814_815_816_817_818_819_820_821_822_823_824_825_826_827_828_829_830_831_832_833_834_835_836_837_838_839_840_841_842_843_844_845_846_847_848_849_850_851_852_853_854_855_856_857_858_859_860_861_862_863_864_865_866_867_868_869_870_871_872_873_874_875_876_877_878_879_880_881_882_883_884_885_886_887_888_889_890_891_892_893_894_895_896_897_898_899_900_901_902_903_904_905_906_907_908_909_910_911_912_913_914_915_916_917_918_919_920_921_922_923_924_925_926_927_928_929_930_931_932_933_934_935_936_937_938_939_940_941_942_943_944_945_946_947_948_949_950_951_952_953_954_955_956_957_958_959_960_961_962_963_964_965_966_967_968_969_970_971_972_973_974_975_976_977_978_979_980_981_982_983_984_985_986_987_988_989_990_991_992_993_994_995_996_997_998_999_1000_1001_1002_1003_1004_1005_1006_1007_1008_1009_1010_1011_1012_1013_1014_1015_1016_1017_1018_1019_1020_1021_1022_1023_1024_1025_1026_1027_1028_1029_1030_1031_1032_1033_1034_1035_1036_1037_1038_1039_1040_1041_1042_1043_1044_1045_1046_1047_1048_1049_1050_1051_1052_1053_1054_1055_1056_1057_1058_1059_1060_1061_1062_1063_1064_1065_1066_1067_1068_1069_1070_1071_1072_1073_1074_1075_1076_1077_1078_1079_1080_1081_1082_1083_1084_1085_1086_1087_1088_1089_1090_1091_1092_1093_1094_1095_1096_1097_1098_1099_1100_1101_1102_1103_1104_1105_1106_1107_1108_1109_1110_1111_1112_1113_1114_1115_1116_1117_1118_1119_1120_1121_1122_1123_1124_1125_1126_1127_1128_1129_1130_1131_1132_1133_1134_1135_1136_1137_1138_1139_1140_1141_1142_1143_1144_1145_1146_1147_1148_1149_1150_1151_1152_1153_1154_1155_1156_1157_1158_1159_1160_1161_1162_1163_1164_1165_1166_1167_1168_1169_1170_1171_1172_1173_1174_1175_1176_1177_1178_1179_1180_1181_1182_1183_1184_1185_1186_1187_1188_1189_1190_1191_1192_1193_1194_1195_1196_1197_1198_1199_1200_1201_1202_1203_1204_1205_1206_1207_1208_1209_1210_1211_1212_1213_1214_1215_1216_1217_1218_1219_1220_1221_1222_1223_1224_1225_1226_1227_1228_1229_1230_1231_1232_1233_1234_1235_1236_1237_1238_1239_1240_1241_1242_1243_1244_1245_1246_1247_1248_1249_1250_1251_1252_1253_1254_1255_1256_1257_1258_1259_1260_1261_1262_1263_1264_1265_1266_1267_1268_1269_1270_1271_1272_1273_1274_1275_1276_1277_1278_1279_1280_1281_1282_1283_1284_1285_1286_1287_1288_1289_1290_1291_1292_1293_1294_1295_1296_1297_1298_1299_1300_1301_1302_1303_1304_1305_1306_1307_1308_1309_1310_1311_1312_1313_1314_1315_1316_1317_1318_1319_1320_1321_1322_1323_1324_1325_1326_1327_1328_1329_1330_1331_1332_1333_1334_1335_1336_1337_1338_1339_1340_1341_\n",
            "\n",
            "1_2_3_4_5_6_7_8_9_10_11_12_13_14_15_16_17_18_19_20_21_22_23_24_25_26_27_28_29_30_31_32_33_34_35_36_37_38_39_40_41_42_43_44_45_46_47_48_49_50_51_52_53_54_55_56_57_58_59_60_61_62_63_64_65_66_67_68_69_70_71_72_73_74_75_76_77_78_79_80_81_82_83_84_85_86_87_88_89_90_91_92_93_94_95_96_97_98_99_100_101_102_103_104_105_106_107_108_109_110_111_112_113_114_115_116_117_118_119_120_121_122_123_124_125_126_127_128_129_130_131_132_133_134_135_136_137_138_139_140_141_142_143_144_145_146_147_148_149_150_151_152_153_154_155_156_157_158_159_160_161_162_163_164_165_166_167_168_169_170_171_172_173_174_175_176_177_178_179_180_181_182_183_184_185_186_187_188_189_190_191_192_193_194_195_196_197_198_199_200_201_202_203_204_205_206_207_208_209_210_211_212_213_214_215_216_217_218_219_220_221_222_223_224_225_226_227_228_229_230_231_232_233_234_235_236_237_238_239_240_241_242_243_244_245_246_247_248_249_250_251_252_253_254_255_256_257_258_259_260_261_262_263_264_265_266_267_268_269_270_271_272_273_274_275_276_277_278_279_280_281_282_283_284_285_286_287_288_289_290_291_292_293_294_295_296_297_298_299_300_301_302_303_304_305_306_307_308_309_310_311_312_313_314_315_316_317_318_319_320_321_322_323_324_325_326_327_328_329_330_331_332_333_334_335_336_337_338_339_340_341_342_343_344_345_346_347_348_349_350_351_352_353_354_355_356_357_358_359_360_361_362_363_364_365_366_367_368_369_370_371_372_373_374_375_376_377_378_379_380_381_382_383_384_385_386_387_388_389_390_391_392_393_394_395_396_397_398_399_400_401_402_403_404_405_406_407_408_409_410_411_412_413_414_415_416_417_418_419_420_421_422_423_424_425_426_427_428_429_430_431_432_433_434_435_436_437_438_439_440_441_442_443_444_445_446_447_448_449_450_451_452_453_454_\n",
            "\n",
            "1_2_3_4_5_6_7_8_9_10_11_12_13_14_15_16_17_18_19_20_21_22_23_24_25_26_27_28_29_30_31_32_33_34_35_36_37_38_39_40_41_42_43_44_45_46_47_48_49_50_51_52_53_54_55_56_57_58_59_60_61_62_63_64_65_66_67_68_69_70_71_72_73_74_75_76_77_78_79_80_81_82_83_84_85_86_87_88_89_90_91_92_93_94_95_96_97_98_99_100_101_102_103_104_105_106_107_108_109_110_111_112_113_114_115_116_117_118_119_120_121_122_123_124_125_126_127_128_129_130_131_132_133_134_135_136_137_138_139_140_141_142_143_144_145_146_147_148_149_150_151_152_153_154_155_156_157_158_159_160_161_162_163_164_165_166_167_168_169_170_171_172_173_174_175_176_177_178_179_180_181_182_183_184_185_186_187_188_189_190_191_192_193_194_195_196_197_198_199_200_201_202_203_204_205_206_207_208_209_210_211_212_213_214_215_216_217_218_219_220_221_222_223_224_225_226_227_228_229_230_231_232_233_234_235_236_237_238_239_240_241_242_243_244_245_246_247_248_249_250_251_252_253_254_255_256_257_258_259_260_261_262_263_264_265_266_267_268_269_270_271_272_273_274_275_276_277_278_279_280_281_282_283_284_285_286_287_288_289_290_291_292_293_294_295_296_297_298_299_300_301_302_303_304_305_306_307_308_309_310_311_312_313_314_315_316_317_318_319_320_321_322_\n",
            "\n",
            "1_2_3_4_5_6_7_8_9_10_11_12_13_14_15_16_17_18_19_20_21_22_23_24_25_26_27_28_29_30_31_32_33_34_35_36_37_38_39_40_41_42_43_44_45_46_47_48_49_50_51_52_53_54_55_56_57_58_59_60_61_62_63_64_65_66_67_68_69_70_71_72_73_74_75_76_77_78_79_80_81_82_83_84_85_86_87_88_89_90_91_92_93_94_95_96_97_98_99_100_101_102_103_104_105_106_107_108_109_110_111_112_113_114_115_116_117_118_119_120_121_122_123_124_125_126_127_128_129_130_131_132_133_134_135_136_137_138_139_140_141_142_143_144_145_146_147_148_149_150_151_152_153_154_155_156_157_158_159_160_161_162_163_164_165_166_167_168_169_170_171_172_173_174_175_176_177_178_179_180_181_182_183_184_185_186_187_188_189_190_191_192_193_194_195_196_197_198_199_200_201_202_203_204_205_206_207_208_209_210_211_212_213_214_215_216_217_218_219_220_221_222_223_224_225_226_227_228_229_230_231_232_233_234_235_236_237_238_239_240_241_242_243_244_245_246_247_248_249_250_251_252_253_254_255_256_257_258_259_260_261_262_263_264_265_266_267_268_269_270_271_272_273_274_275_276_277_278_279_280_281_282_283_284_285_286_287_288_289_290_291_292_293_294_295_296_297_298_299_300_301_302_303_304_305_306_307_308_309_310_311_312_313_314_315_316_317_318_319_320_321_322_323_324_325_326_327_328_329_330_331_332_333_334_335_336_337_338_339_340_341_342_343_344_345_346_347_348_349_350_351_352_353_354_355_356_357_358_359_360_361_362_363_364_365_366_367_368_369_370_371_372_373_374_375_376_377_378_379_380_381_382_383_384_385_386_387_388_389_390_391_392_393_394_395_396_397_398_399_400_401_402_403_404_405_406_407_408_409_410_411_412_413_414_415_416_417_418_419_420_421_422_423_424_425_426_427_428_429_430_431_432_433_434_435_436_437_438_439_440_441_442_443_444_445_446_447_448_449_450_451_452_453_454_455_456_457_458_459_460_461_462_463_464_465_466_467_468_469_470_471_472_473_474_475_476_477_478_479_480_481_482_483_484_485_486_487_488_489_490_491_492_493_494_495_496_497_498_499_500_501_502_503_504_505_506_507_508_509_510_511_512_513_514_515_516_517_518_519_520_521_522_523_524_525_526_527_528_529_530_531_532_533_534_535_536_537_538_539_540_541_542_543_544_545_546_547_548_549_550_551_552_553_554_555_556_557_558_559_560_561_562_563_564_565_566_567_568_569_570_571_572_573_574_575_576_577_578_579_580_581_582_583_584_585_586_587_588_589_590_591_592_593_594_595_596_597_598_599_600_601_602_603_604_605_606_607_608_609_610_611_612_613_614_615_616_617_618_619_620_621_622_623_624_625_626_627_628_629_630_631_632_633_634_635_636_637_638_639_640_641_642_643_644_645_646_647_648_649_650_651_652_653_654_655_656_657_658_659_660_661_662_663_664_665_666_667_668_669_670_671_672_673_674_675_676_677_678_679_680_681_682_683_684_685_686_687_688_689_690_691_692_693_694_695_696_697_698_699_700_701_702_703_704_705_706_707_708_709_710_711_712_713_714_715_716_717_718_719_720_721_722_723_724_725_726_727_728_729_730_731_732_733_734_735_736_737_738_739_740_741_742_743_744_745_746_747_748_749_750_751_752_753_754_755_756_757_758_759_760_761_762_763_764_765_766_767_768_769_770_771_772_773_774_775_776_777_778_779_780_781_782_783_784_785_786_787_788_789_790_791_792_793_794_795_796_797_798_799_800_801_802_803_804_805_806_807_808_809_810_811_812_813_814_815_816_817_818_819_820_821_822_823_824_825_826_827_828_829_830_831_832_833_834_835_836_837_838_839_840_841_842_843_844_845_846_847_848_849_850_851_852_853_854_855_856_857_858_859_860_861_862_863_864_865_866_867_868_869_870_871_872_873_874_875_876_877_878_879_880_881_882_883_884_885_886_887_888_889_890_891_892_893_894_895_896_897_898_899_900_901_902_903_904_905_906_907_908_909_910_911_912_913_914_915_916_917_918_919_920_921_922_923_924_925_926_927_928_929_930_931_932_933_934_935_936_937_938_939_940_941_942_943_944_945_946_947_948_949_950_951_952_953_954_955_956_957_958_959_960_961_962_963_964_965_966_967_968_969_970_971_972_973_974_975_976_977_978_979_980_981_982_983_984_985_986_987_988_989_990_991_992_993_994_995_996_997_998_999_1000_1001_1002_1003_1004_1005_1006_1007_1008_1009_1010_1011_1012_1013_1014_1015_1016_1017_1018_1019_1020_1021_1022_1023_1024_1025_1026_1027_1028_1029_1030_1031_1032_1033_1034_1035_1036_1037_1038_1039_1040_1041_1042_1043_1044_1045_1046_1047_1048_1049_1050_1051_1052_1053_1054_1055_1056_1057_1058_1059_1060_1061_1062_1063_1064_1065_1066_1067_1068_1069_1070_1071_1072_1073_1074_1075_1076_1077_1078_1079_1080_1081_1082_1083_1084_1085_1086_1087_1088_1089_1090_1091_1092_1093_1094_1095_1096_1097_1098_1099_1100_1101_1102_1103_1104_1105_1106_1107_1108_1109_1110_1111_1112_1113_1114_1115_1116_1117_1118_1119_1120_1121_1122_1123_1124_1125_1126_1127_1128_1129_1130_1131_1132_1133_1134_1135_1136_1137_1138_1139_1140_1141_1142_1143_1144_1145_1146_1147_1148_1149_1150_1151_1152_1153_1154_1155_1156_1157_1158_1159_1160_1161_1162_1163_1164_1165_1166_1167_1168_1169_1170_1171_1172_1173_1174_1175_1176_1177_1178_1179_1180_1181_1182_1183_1184_1185_1186_1187_1188_1189_1190_1191_1192_1193_1194_1195_1196_1197_1198_1199_1200_1201_1202_1203_1204_1205_1206_1207_1208_1209_1210_1211_1212_1213_1214_1215_1216_1217_1218_1219_1220_1221_1222_1223_1224_1225_1226_1227_1228_1229_1230_1231_1232_1233_1234_1235_1236_1237_1238_1239_1240_1241_1242_1243_1244_1245_1246_1247_1248_1249_1250_1251_1252_1253_1254_1255_1256_1257_1258_1259_1260_1261_1262_1263_1264_1265_1266_1267_1268_1269_1270_1271_1272_1273_1274_1275_1276_1277_1278_1279_1280_1281_1282_1283_1284_1285_1286_1287_1288_1289_1290_1291_1292_1293_1294_1295_1296_1297_1298_1299_1300_1301_1302_1303_1304_1305_1306_1307_1308_1309_1310_1311_1312_1313_1314_1315_1316_1317_1318_1319_1320_1321_1322_1323_1324_1325_1326_1327_1328_1329_1330_1331_1332_1333_1334_1335_1336_1337_1338_1339_1340_1341_1342_1343_1344_1345_1346_1347_1348_1349_1350_1351_1352_1353_1354_1355_1356_1357_1358_1359_1360_1361_1362_1363_1364_1365_1366_1367_1368_1369_1370_1371_1372_1373_1374_1375_1376_1377_1378_1379_1380_1381_1382_1383_1384_1385_1386_1387_1388_1389_1390_1391_1392_1393_1394_1395_1396_1397_1398_1399_1400_1401_1402_1403_1404_1405_1406_1407_1408_1409_1410_1411_1412_1413_1414_1415_1416_1417_1418_1419_1420_1421_1422_1423_1424_1425_1426_1427_1428_1429_1430_1431_1432_1433_1434_1435_1436_1437_1438_1439_1440_1441_1442_1443_1444_1445_1446_1447_1448_1449_1450_1451_1452_1453_1454_1455_1456_1457_1458_1459_1460_1461_1462_1463_1464_1465_1466_1467_1468_1469_1470_1471_1472_1473_1474_1475_1476_1477_1478_1479_1480_1481_1482_1483_1484_1485_1486_1487_1488_1489_1490_1491_1492_1493_1494_1495_1496_1497_1498_1499_1500_1501_1502_1503_1504_1505_1506_1507_1508_1509_1510_1511_1512_1513_1514_1515_1516_1517_1518_1519_1520_1521_1522_1523_1524_1525_1526_1527_1528_1529_1530_1531_1532_1533_1534_1535_1536_1537_1538_1539_1540_1541_1542_1543_1544_1545_1546_1547_1548_1549_1550_1551_1552_1553_1554_1555_1556_1557_1558_1559_1560_1561_1562_1563_1564_1565_1566_1567_1568_1569_1570_1571_1572_1573_1574_1575_1576_1577_1578_1579_1580_1581_1582_1583_1584_1585_1586_1587_1588_1589_1590_1591_1592_1593_1594_1595_1596_1597_1598_1599_1600_1601_1602_1603_1604_1605_1606_1607_1608_1609_1610_1611_1612_1613_1614_1615_1616_1617_1618_1619_1620_1621_1622_1623_1624_1625_1626_1627_1628_1629_1630_1631_1632_1633_1634_1635_1636_1637_1638_1639_1640_1641_1642_1643_1644_1645_1646_1647_1648_1649_1650_1651_1652_1653_1654_1655_1656_1657_1658_1659_1660_1661_1662_1663_1664_1665_1666_1667_1668_1669_1670_1671_1672_1673_1674_1675_1676_1677_1678_1679_1680_1681_1682_1683_1684_1685_1686_1687_1688_1689_1690_1691_1692_1693_1694_1695_1696_1697_1698_1699_1700_1701_1702_1703_1704_1705_1706_1707_1708_1709_1710_1711_1712_1713_1714_1715_1716_1717_1718_1719_1720_1721_1722_1723_1724_1725_1726_1727_1728_1729_1730_1731_1732_1733_1734_1735_1736_1737_1738_1739_1740_1741_1742_1743_1744_1745_1746_1747_1748_1749_1750_1751_1752_1753_1754_1755_1756_1757_1758_1759_1760_1761_1762_1763_1764_1765_1766_1767_1768_1769_1770_1771_1772_1773_1774_1775_1776_1777_1778_1779_1780_1781_1782_1783_1784_1785_1786_1787_1788_1789_1790_1791_1792_1793_1794_1795_1796_1797_1798_1799_1800_1801_1802_1803_1804_1805_1806_1807_1808_1809_1810_1811_1812_1813_1814_1815_1816_1817_1818_1819_1820_1821_1822_1823_1824_1825_1826_1827_1828_1829_1830_1831_1832_1833_1834_1835_1836_1837_1838_1839_1840_1841_1842_1843_1844_1845_1846_1847_1848_1849_1850_1851_1852_1853_1854_1855_1856_1857_1858_1859_1860_1861_1862_1863_1864_1865_1866_1867_1868_1869_1870_1871_1872_1873_1874_1875_1876_1877_1878_1879_1880_1881_1882_1883_1884_1885_1886_1887_1888_1889_1890_1891_1892_1893_1894_1895_1896_1897_1898_1899_1900_1901_1902_1903_1904_1905_1906_1907_1908_1909_1910_1911_1912_1913_1914_1915_1916_1917_1918_1919_1920_1921_1922_1923_1924_1925_1926_1927_1928_1929_1930_1931_1932_1933_1934_1935_1936_1937_1938_1939_1940_1941_1942_1943_1944_1945_1946_1947_1948_1949_1950_1951_1952_1953_1954_1955_1956_1957_1958_1959_1960_1961_1962_1963_1964_1965_1966_1967_1968_1969_1970_1971_1972_1973_1974_1975_1976_1977_1978_1979_1980_1981_1982_1983_1984_1985_1986_1987_1988_1989_1990_1991_1992_1993_1994_1995_1996_1997_1998_1999_2000_2001_2002_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022_2023_2024_2025_2026_2027_2028_2029_2030_2031_2032_2033_2034_2035_2036_2037_2038_2039_2040_2041_2042_2043_2044_2045_2046_2047_2048_2049_2050_2051_2052_2053_2054_2055_2056_2057_2058_2059_2060_2061_2062_2063_2064_2065_2066_2067_2068_2069_2070_2071_2072_2073_2074_2075_2076_2077_2078_2079_2080_2081_2082_2083_2084_2085_2086_2087_2088_2089_2090_2091_2092_2093_2094_2095_2096_2097_2098_2099_2100_2101_2102_2103_2104_2105_2106_2107_2108_2109_2110_2111_2112_2113_2114_2115_2116_2117_2118_2119_2120_2121_2122_2123_2124_2125_2126_2127_2128_2129_2130_2131_2132_2133_2134_2135_2136_2137_2138_2139_2140_2141_2142_2143_2144_2145_2146_2147_2148_2149_2150_2151_2152_2153_2154_2155_2156_2157_2158_2159_2160_2161_2162_2163_2164_2165_2166_2167_2168_2169_2170_2171_2172_2173_2174_2175_2176_2177_2178_2179_2180_2181_2182_2183_2184_2185_2186_2187_2188_2189_2190_2191_2192_2193_2194_2195_2196_2197_2198_2199_2200_2201_2202_2203_2204_2205_2206_2207_2208_2209_2210_2211_2212_2213_2214_2215_2216_2217_2218_2219_2220_2221_2222_2223_2224_2225_2226_2227_2228_2229_2230_2231_2232_2233_2234_2235_2236_2237_2238_2239_2240_2241_2242_2243_2244_2245_2246_2247_2248_2249_2250_2251_2252_2253_2254_2255_2256_2257_2258_2259_2260_2261_2262_2263_2264_2265_2266_2267_2268_2269_2270_2271_2272_2273_2274_2275_2276_2277_2278_2279_2280_2281_2282_2283_2284_2285_2286_2287_2288_2289_2290_2291_2292_2293_2294_2295_2296_2297_2298_2299_2300_2301_2302_2303_2304_2305_2306_2307_2308_2309_2310_2311_2312_2313_2314_2315_2316_2317_2318_2319_2320_2321_2322_2323_2324_2325_2326_2327_2328_2329_2330_2331_2332_2333_2334_2335_2336_2337_2338_2339_2340_2341_2342_2343_2344_2345_2346_2347_2348_2349_2350_2351_2352_2353_2354_2355_2356_2357_2358_2359_2360_2361_2362_2363_2364_2365_2366_2367_2368_2369_2370_2371_2372_2373_2374_2375_2376_2377_2378_2379_2380_2381_2382_2383_2384_2385_2386_2387_2388_2389_2390_2391_2392_2393_2394_2395_2396_2397_2398_2399_2400_2401_2402_2403_2404_2405_2406_2407_2408_2409_2410_2411_2412_2413_2414_2415_2416_2417_2418_2419_2420_2421_2422_2423_2424_2425_2426_2427_2428_2429_2430_2431_2432_2433_2434_2435_2436_2437_2438_2439_2440_2441_2442_2443_2444_2445_2446_2447_2448_2449_2450_2451_2452_2453_2454_2455_2456_2457_2458_2459_2460_2461_2462_2463_2464_2465_2466_2467_2468_2469_2470_2471_2472_2473_2474_2475_2476_2477_2478_2479_2480_2481_2482_2483_2484_2485_2486_2487_2488_2489_2490_2491_2492_2493_2494_2495_2496_2497_2498_2499_2500_2501_2502_2503_2504_2505_2506_2507_2508_2509_2510_2511_2512_2513_2514_2515_2516_2517_2518_2519_2520_2521_2522_2523_2524_2525_2526_2527_2528_2529_2530_2531_2532_2533_2534_2535_2536_2537_2538_2539_2540_2541_2542_2543_2544_2545_2546_2547_2548_2549_2550_2551_2552_2553_2554_2555_2556_2557_2558_2559_2560_2561_2562_2563_2564_2565_2566_2567_2568_2569_2570_2571_2572_2573_2574_2575_2576_2577_2578_2579_2580_2581_2582_2583_2584_2585_2586_2587_2588_2589_2590_2591_2592_2593_2594_2595_2596_2597_2598_2599_2600_2601_2602_2603_2604_2605_2606_2607_2608_2609_2610_2611_2612_2613_2614_2615_2616_2617_2618_2619_2620_2621_2622_2623_2624_2625_2626_2627_2628_2629_2630_2631_2632_2633_2634_2635_2636_2637_2638_2639_2640_2641_2642_2643_2644_2645_2646_2647_2648_2649_2650_2651_2652_2653_2654_2655_2656_2657_2658_2659_2660_2661_2662_2663_2664_2665_2666_2667_2668_2669_2670_2671_2672_2673_2674_2675_2676_2677_2678_2679_2680_2681_2682_2683_2684_2685_2686_2687_2688_2689_2690_2691_2692_2693_2694_2695_2696_2697_2698_2699_2700_2701_2702_2703_2704_2705_2706_2707_2708_2709_2710_2711_2712_2713_2714_2715_2716_2717_2718_2719_2720_2721_2722_2723_2724_2725_2726_2727_2728_2729_2730_2731_2732_2733_2734_2735_2736_2737_2738_2739_2740_2741_2742_2743_2744_2745_2746_2747_2748_2749_2750_2751_2752_2753_2754_2755_2756_2757_2758_2759_2760_2761_2762_2763_2764_2765_2766_2767_2768_2769_2770_2771_2772_2773_2774_2775_2776_2777_2778_2779_2780_2781_2782_2783_2784_2785_2786_2787_2788_2789_2790_2791_2792_2793_2794_2795_2796_2797_2798_2799_2800_2801_2802_2803_2804_2805_2806_2807_2808_2809_2810_2811_2812_2813_2814_2815_2816_2817_2818_2819_2820_2821_2822_2823_2824_2825_2826_2827_2828_2829_2830_2831_2832_2833_2834_2835_2836_2837_2838_2839_2840_2841_2842_2843_2844_2845_2846_2847_2848_2849_2850_2851_2852_2853_2854_2855_2856_2857_2858_2859_2860_2861_2862_2863_2864_2865_2866_2867_2868_2869_2870_2871_2872_2873_2874_2875_2876_2877_2878_2879_2880_2881_2882_2883_2884_2885_2886_2887_2888_2889_2890_2891_2892_2893_2894_2895_2896_2897_2898_2899_2900_2901_2902_2903_2904_2905_2906_2907_2908_2909_2910_2911_2912_2913_2914_2915_2916_2917_2918_2919_2920_2921_2922_2923_2924_2925_2926_2927_2928_2929_2930_2931_2932_2933_2934_2935_2936_2937_2938_2939_2940_2941_2942_2943_2944_2945_2946_2947_2948_2949_2950_2951_2952_2953_2954_2955_2956_2957_2958_2959_2960_2961_2962_2963_2964_2965_2966_2967_2968_2969_2970_2971_2972_2973_2974_2975_2976_2977_2978_2979_2980_2981_2982_2983_2984_2985_2986_2987_2988_2989_2990_2991_2992_2993_2994_2995_2996_2997_2998_2999_3000_3001_3002_3003_3004_3005_3006_3007_3008_3009_3010_3011_3012_3013_3014_3015_3016_3017_3018_3019_3020_3021_3022_3023_3024_3025_3026_3027_3028_3029_3030_3031_3032_3033_3034_3035_3036_3037_3038_3039_3040_3041_3042_3043_3044_3045_3046_3047_3048_3049_3050_3051_3052_3053_3054_3055_3056_3057_3058_3059_3060_3061_3062_3063_3064_3065_3066_3067_3068_3069_3070_3071_3072_3073_3074_3075_3076_3077_3078_3079_3080_3081_3082_3083_3084_3085_3086_3087_3088_3089_3090_3091_3092_3093_3094_3095_3096_3097_3098_3099_3100_3101_3102_3103_3104_3105_3106_3107_3108_3109_3110_3111_3112_3113_3114_3115_3116_3117_3118_3119_3120_3121_3122_3123_3124_3125_3126_3127_3128_3129_3130_3131_3132_3133_3134_3135_3136_3137_3138_3139_3140_3141_3142_3143_3144_3145_3146_3147_3148_3149_3150_3151_3152_3153_3154_3155_3156_3157_3158_3159_3160_3161_3162_3163_3164_3165_3166_3167_3168_3169_3170_3171_3172_3173_3174_3175_3176_3177_3178_3179_3180_3181_3182_3183_3184_3185_3186_3187_3188_3189_3190_3191_3192_3193_3194_3195_3196_3197_3198_3199_3200_3201_3202_3203_3204_3205_3206_3207_3208_3209_3210_3211_3212_3213_3214_3215_3216_3217_3218_3219_3220_3221_3222_3223_3224_3225_3226_3227_3228_3229_3230_3231_3232_3233_3234_3235_3236_3237_3238_3239_3240_3241_3242_3243_3244_3245_3246_3247_3248_3249_3250_3251_3252_3253_3254_3255_3256_3257_3258_3259_3260_3261_3262_3263_3264_3265_3266_3267_3268_3269_3270_3271_3272_3273_3274_3275_3276_3277_3278_3279_3280_3281_3282_3283_3284_3285_3286_3287_3288_3289_3290_3291_3292_3293_3294_3295_3296_3297_3298_3299_3300_3301_3302_3303_3304_3305_3306_3307_3308_3309_3310_3311_3312_3313_3314_3315_3316_3317_3318_3319_3320_3321_3322_3323_3324_3325_3326_3327_3328_3329_3330_3331_3332_3333_3334_3335_3336_3337_3338_3339_3340_3341_3342_3343_3344_3345_3346_3347_3348_3349_3350_3351_3352_3353_3354_3355_3356_3357_3358_3359_3360_3361_3362_3363_3364_3365_3366_3367_3368_3369_3370_3371_3372_3373_3374_3375_3376_3377_3378_3379_3380_3381_3382_3383_3384_3385_3386_3387_3388_3389_3390_3391_3392_3393_3394_3395_3396_3397_3398_3399_3400_3401_3402_3403_3404_3405_3406_3407_3408_3409_3410_3411_3412_3413_3414_3415_3416_3417_3418_3419_3420_3421_3422_3423_3424_3425_3426_3427_3428_3429_3430_3431_3432_3433_3434_3435_3436_3437_3438_3439_3440_3441_3442_3443_3444_3445_3446_3447_3448_3449_3450_3451_3452_3453_3454_3455_3456_3457_3458_3459_3460_3461_3462_3463_3464_3465_3466_3467_3468_3469_3470_3471_3472_3473_3474_3475_3476_3477_3478_3479_3480_3481_3482_3483_3484_3485_3486_3487_3488_3489_3490_3491_3492_3493_3494_3495_3496_3497_3498_3499_3500_3501_3502_3503_3504_3505_3506_3507_3508_3509_3510_3511_3512_3513_3514_3515_3516_3517_3518_3519_3520_3521_3522_3523_3524_3525_3526_3527_3528_3529_3530_3531_3532_3533_3534_3535_3536_3537_3538_3539_3540_3541_3542_3543_3544_3545_3546_3547_3548_3549_3550_3551_3552_3553_3554_3555_3556_3557_3558_3559_3560_3561_3562_3563_3564_3565_3566_3567_3568_3569_3570_3571_3572_3573_3574_3575_3576_3577_3578_3579_3580_3581_3582_3583_3584_3585_3586_3587_3588_3589_3590_3591_3592_3593_3594_3595_3596_3597_3598_3599_3600_3601_3602_3603_3604_3605_3606_3607_3608_3609_3610_3611_3612_3613_3614_3615_3616_3617_3618_3619_3620_3621_3622_3623_3624_3625_3626_3627_3628_3629_3630_3631_3632_3633_3634_3635_3636_3637_3638_3639_3640_3641_3642_3643_3644_3645_3646_3647_3648_3649_3650_3651_3652_3653_3654_3655_3656_3657_3658_3659_3660_3661_3662_3663_3664_3665_3666_3667_3668_3669_3670_3671_3672_3673_3674_3675_3676_3677_3678_3679_3680_3681_3682_3683_3684_3685_3686_3687_3688_3689_3690_3691_3692_3693_3694_3695_3696_3697_3698_3699_3700_3701_3702_3703_3704_3705_3706_3707_3708_3709_3710_3711_3712_3713_3714_3715_3716_3717_3718_3719_3720_3721_3722_3723_3724_3725_3726_3727_3728_3729_3730_3731_3732_3733_3734_3735_3736_3737_3738_3739_3740_3741_3742_3743_3744_3745_3746_3747_3748_3749_3750_3751_3752_3753_3754_3755_3756_3757_3758_3759_3760_3761_3762_3763_3764_3765_class numbers 5\n",
            "prediction number: 5882\n",
            "true labels: 5882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We use Support Vector classifier as a classifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#importing packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "### matrics\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "-wPwnaXIGOU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  make a directory for storing figures\n",
        "y_preD=probaa\n",
        "cm = confusion_matrix(y_test, y_preD)\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index = ['Normal','Tuberculosis','covid19','Pneumonia'],\n",
        "                     columns = ['Normal','Tuberculosis','covid19','Pneumonia'])\n",
        "\n",
        "#Plotting the confusion matrix\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm_df,cmap='cividis', annot=True, fmt='d')\n",
        "#plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actal Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "\n",
        "###save confusion matrix to fig directory ...keep the image file name as h5 file name. ex:  breastCancer_geometric.h5 >>> breastCancer_geometric_con.png\n",
        "plt.savefig(\"/content/drive/MyDrive/rhd_model/csv/confusion_matrix.png\", dpi = 300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "wSLGmZ41GSxb",
        "outputId": "6a8b2fa5-42e1-48d9-9760-cf7da3a8ef1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preD=probaa\n",
        "y_val=y_test\n",
        "\n",
        "confusion_matrix=cm\n",
        "\n",
        "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
        "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
        "TP = np.diag(confusion_matrix)\n",
        "TN = len(y_val) - (FP + FN + TP)\n",
        "\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP)\n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FP)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "\n",
        "# Overall accuracy\n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "from numpy import mean\n",
        "\n",
        "MAE=mean_absolute_error(y_val, y_preD)\n",
        "MSE=mean_squared_error(y_val, y_preD)\n",
        "F1=2*((mean(PPV)*mean(TPR))/(mean(PPV)+mean(TPR)))\n",
        "\n",
        "#print(\"ACC=   \",mean(ACC)*100)\n",
        "\n",
        "print(\"Rec=   \",mean(TPR)*100)\n",
        "print(\"Spe=   \",mean(TNR)*100)\n",
        "print(\"Pre=   \",mean(PPV)*100)\n",
        "print(\"FPR=   \",mean(FPR)*100)\n",
        "print(\"FNR=   \",mean(FNR)*100)\n",
        "print(\"NPV=   \",mean(NPV)*100)\n",
        "print(\"FDR=   \",mean(FDR)*100)\n",
        "print(\"F1=    \",mean(F1)*100)\n",
        "\n",
        "print(\"MAE   =\",MAE*100)\n",
        "print(\"RMSE  =\",math.sqrt(MSE)*100)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRSjOqdaGsSU",
        "outputId": "c7144972-18e8-46ec-bcae-545837958adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rec=    99.33167764504236\n",
            "Spe=    99.88472471904385\n",
            "Pre=    99.78314885362612\n",
            "FPR=    0.11527528095615146\n",
            "FNR=    0.6683223549576391\n",
            "NPV=    99.94822542301495\n",
            "FDR=    0.21685114637389888\n",
            "F1=     99.55690141840793\n",
            "MAE   = 0.27201632097925876\n",
            "RMSE  = 7.1416426810371165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KAtqcGH5NrLi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}